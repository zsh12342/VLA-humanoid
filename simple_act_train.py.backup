#!/usr/bin/env python3
"""
VLA项目统一训练文件 - 包含所有训练相关的代码
符合CRITICAL PRINCIPLE的两层架构：指令分类 + 动作预测
集成了动作质量验证系统
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
import os
import json
from datetime import datetime
from typing import Dict, Optional, List, Any
from tqdm import tqdm
import math
import sys
from pathlib import Path
from collections import defaultdict

# 导入必要的模块
from modules.direct_action_predictor import create_direct_action_model
from fixed_dataset import FixedTrajectoryDataset
from action_quality_validator import ActionQualityValidator, TrainingQualityMonitor
from improved_act_model import ImprovedKeyJointACTGenerator

# ==============================================
# 1. 核心模型架构 - 改进的关键关节专注ACT模型
# ==============================================

class EnhancedTimeEncoding(nn.Module):
    """增强的时间编码模块"""
    def __init__(self, hidden_dim):
        super().__init__()
        self.hidden_dim = hidden_dim
        
        # 多尺度时间编码
        self.linear_encoding = nn.Linear(1, hidden_dim // 4)
        self.sinusoidal_encoding = nn.Linear(1, hidden_dim // 4)
        self.phase_encoding = nn.Linear(1, hidden_dim // 4)
        self.frequency_encoding = nn.Linear(1, hidden_dim // 4)
        
        # 组合层
        self.combination = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1)
        )
    
    def forward(self, t):
        # t: [batch_size, seq_len] or [batch_size, seq_len, 1]
        if t.dim() == 2:
            t = t.unsqueeze(-1)
        
        # 线性编码
        linear_feat = self.linear_encoding(t)
        
        # 正弦编码
        sinusoidal_feat = torch.sin(self.sinusoidal_encoding(t)) + torch.cos(self.sinusoidal_encoding(t))
        
        # 相位编码
        phase_feat = torch.sin(2 * np.pi * self.phase_encoding(t))
        
        # 频率编码
        freq_feat = torch.sin(4 * np.pi * self.frequency_encoding(t))
        
        # 组合所有特征
        combined = torch.cat([linear_feat, sinusoidal_feat, phase_feat, freq_feat], dim=-1)
        return self.combination(combined)

class ImprovedKeyJointACTGenerator(nn.Module):
    """
    改进的关键关节专注ACT生成器 - 解决中间状态预测衰减问题
    核心改进：
    1. 动作强度调节机制
    2. 增强的时间编码
    3. 状态感知增强
    4. 多尺度预测
    """
    """
    
    def __init__(self, config: Dict):
        super().__init__()
        
        # 基础参数
        self.state_dim = config['state_dim']
        self.action_dim = config['action_dim']
        self.num_instructions = config['num_instructions']
        self.hidden_dim = config['hidden_dim']
        self.trajectory_length = config.get('trajectory_length', 32)
        self.dropout = config['dropout']
        
        # 关键关节数量 - 每个指令重点关注的前N个关节
        self.key_joints_per_instruction = config.get('key_joints_per_instruction', 8)
        
        # 改进的组件
        self.enhanced_time_encoding = EnhancedTimeEncoding(self.hidden_dim // 4)
        
        # 动作强度调节器
        self.action_intensity_regulator = nn.Sequential(
            nn.Linear(self.hidden_dim + 64, self.hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(self.hidden_dim // 2, self.hidden_dim // 4),
            nn.ReLU(),
            nn.Linear(self.hidden_dim // 4, 1),
            nn.Sigmoid()
        )
        
        # 状态感知增强器
        self.state_aware_enhancer = nn.Sequential(
            nn.Linear(self.hidden_dim + self.state_dim, self.hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(self.hidden_dim, self.hidden_dim)
        )
        
        # 第一层：指令分类器
        self.instruction_classifier = nn.Sequential(
            nn.Linear(self.hidden_dim, 128),
            nn.ReLU(),
            nn.Dropout(self.dropout),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(self.dropout),
            nn.Linear(64, self.num_instructions)
        )
        
        # 增强的状态编码器
        self.state_encoder = nn.Sequential(
            nn.Linear(self.state_dim, self.hidden_dim),
            nn.ReLU(),
            nn.Dropout(self.dropout),
            nn.Linear(self.hidden_dim, self.hidden_dim * 2)
        )
        
        # 指令嵌入
        self.instruction_embedding = nn.Embedding(self.num_instructions, 64)
        super().__init__()
        
        # 基础参数
        self.state_dim = config['state_dim']
        self.action_dim = config['action_dim']
        self.num_instructions = config['num_instructions']
        self.hidden_dim = config['hidden_dim']
        self.trajectory_length = 32  # 预测后32步，简化学习任务
        self.dropout = config['dropout']
        
        # 关键关节数量 - 每个指令重点关注的前N个关节
        self.key_joints_per_instruction = config.get('key_joints_per_instruction', 8)
        
        # 差分预测标志
        self.predict_differences = config.get('predict_differences', True)
        
        # 第一层：指令分类器
        self.instruction_classifier = nn.Sequential(
            nn.Linear(self.hidden_dim, 128),
            nn.ReLU(),
            nn.Dropout(self.dropout),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(self.dropout),
            nn.Linear(64, self.num_instructions)
        )
        
        # 状态编码器
        self.state_encoder = nn.Sequential(
            nn.Linear(self.state_dim, self.hidden_dim),
            nn.ReLU(),
            nn.Dropout(self.dropout),
            nn.Linear(self.hidden_dim, self.hidden_dim)
        )
        
        # 指令嵌入
        self.instruction_embedding = nn.Embedding(self.num_instructions, 64)
        
        # 时间编码
        self.time_encoding = nn.Sequential(
            nn.Linear(1, self.hidden_dim // 4),
            nn.ReLU(),
            nn.Linear(self.hidden_dim // 4, self.hidden_dim // 4)
        )
        
        # 时序编码器 - 使用Transformer更好地处理时序依赖
        temporal_input_size = self.hidden_dim + 64 + self.hidden_dim // 4  # state + instruction + time
        
        # 关节重要性分析器 - 为每个指令分析关节重要性
        self.joint_importance_analyzer = nn.Sequential(
            nn.Linear(self.hidden_dim + 64, 128),
            nn.ReLU(),
            nn.Dropout(self.dropout),
            nn.Linear(128, self.action_dim),
            nn.Sigmoid()  # 输出每个关节的重要性权重
        )
        
        # 第二层：指令专用的关键关节预测器
        self.key_joint_predictors = nn.ModuleList([
            nn.Sequential(
                nn.Linear(temporal_input_size, 256),
                nn.ReLU(),
                nn.Dropout(self.dropout),
                nn.Linear(256, 128),
                nn.ReLU(),
                nn.Dropout(self.dropout),
                nn.Linear(128, self.key_joints_per_instruction)  # 只预测关键关节
            ) for _ in range(self.num_instructions)
        ])
        
        # 完整关节输出层 - 从关键关节扩展到所有关节
        self.full_joint_expander = nn.Sequential(
            nn.Linear(self.key_joints_per_instruction, 128),
            nn.ReLU(),
            nn.Dropout(self.dropout),
            nn.Linear(128, self.action_dim)
        )
        
        # 时序编码器
        self.temporal_encoder = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(
                d_model=temporal_input_size,
                nhead=8,
                dim_feedforward=self.hidden_dim,
                dropout=self.dropout,
                batch_first=True
            ),
            num_layers=3
        )
        
        # 损失权重
        self.classification_weight = 10.0
        self.diversity_weight = 5.0
        
        # 信号放大参数
        self.signal_amplification = config.get('signal_amplification', 10.0)
        
        # 权重初始化
        self._initialize_weights()
    
    def _initialize_weights(self):
        """权重初始化 - 使用更保守的初始化策略"""
        for name, module in self.named_modules():
            if isinstance(module, nn.Linear):
                # 使用更小的初始化范围，防止早期训练不稳定
                if module.weight.dim() >= 2:  # 确保至少是2维张量
                    nn.init.xavier_uniform_(module.weight, gain=0.5)
                else:
                    nn.init.normal_(module.weight, mean=0.0, std=0.02)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0.0)
            elif isinstance(module, nn.Embedding):
                nn.init.normal_(module.weight, mean=0.0, std=0.05)
            elif isinstance(module, nn.TransformerEncoderLayer):
                for param_name, param in module.named_parameters():
                    if 'weight' in param_name and param.dim() >= 2:
                        nn.init.xavier_uniform_(param, gain=0.5)
                    elif 'bias' in param_name:
                        nn.init.constant_(param, 0.0)
    
    def forward(self, start_states, instruction_ids, target_actions=None):
        """前向传播"""
        batch_size = start_states.size(0)
        device = start_states.device
        
        # 状态编码
        state_encoded = self.state_encoder(start_states)
        
        # 第一层：指令分类
        instruction_logits = self.instruction_classifier(state_encoded)
        
        # 指令嵌入
        instruction_emb = self.instruction_embedding(instruction_ids)
        
        # 分析关节重要性
        joint_importance_input = torch.cat([state_encoded, instruction_emb], dim=-1)
        joint_importance = self.joint_importance_analyzer(joint_importance_input)
        
        # 时间编码
        time_steps = torch.linspace(0, 1, self.trajectory_length, device=device)
        time_embed = self.time_encoding(time_steps.unsqueeze(-1)).unsqueeze(0).expand(batch_size, -1, -1)
        
        # 准备时序输入
        state_expanded = state_encoded.unsqueeze(1).expand(-1, self.trajectory_length, -1)
        instruction_expanded = instruction_emb.unsqueeze(1).expand(-1, self.trajectory_length, -1)
        
        temporal_input = torch.cat([state_expanded, instruction_expanded, time_embed], dim=-1)
        
        # 时序编码
        temporal_output = self.temporal_encoder(temporal_input)
        
        # 第二层：指令专用的关键关节预测
        key_joint_actions = []
        for i in range(batch_size):
            instruction_id = instruction_ids[i].item()
            predictor = self.key_joint_predictors[instruction_id]
            
            # 预测关键关节
            key_action = predictor(temporal_output[i])
            key_joint_actions.append(key_action)
        
        key_joint_actions = torch.stack(key_joint_actions, dim=0)
        
        # 扩展到完整关节输出
        full_joint_actions = []
        for t in range(self.trajectory_length):
            key_at_t = key_joint_actions[:, t, :]
            full_at_t = self.full_joint_expander(key_at_t)
            full_joint_actions.append(full_at_t)
        
        predicted_actions = torch.stack(full_joint_actions, dim=1)
        
        return predicted_actions, instruction_logits, joint_importance, key_joint_actions
    
    def get_key_joint_indices(self, joint_importance, instruction_ids):
        """获取关键关节的索引"""
        batch_size = joint_importance.size(0)
        key_indices = []
        
        for i in range(batch_size):
            instruction_id = instruction_ids[i].item()
            importance = joint_importance[i]
            
            # 选择重要性最高的前N个关节
            top_values, top_indices = torch.topk(importance, self.key_joints_per_instruction)
            key_indices.append(top_indices)
        
        return torch.stack(key_indices, dim=0)

# ==============================================
# 2. 数据集类
# ==============================================

class KeyJointDataset(Dataset):
    """关键关节数据集 - 平衡采样策略"""
    
    def __init__(self, data_dir: str, file_names: list, trajectory_length: int = 32):
        self.data_dir = data_dir
        self.file_names = file_names
        self.trajectory_length = trajectory_length
        
        # 指令映射
        self.instruction_to_id = {'wave': 0, 'welcome': 1}
        
        # 使用改进的平衡采样策略
        self.samples = self._balanced_sampling_strategy()
        
        print(f"采样结果: 总样本数 {len(self.samples)}")
        instruction_counts = {}
        for instruction, _, _ in self.samples:
            instruction_counts[instruction] = instruction_counts.get(instruction, 0) + 1
        for instruction, count in instruction_counts.items():
            print(f"  {instruction}: {count} 个样本")
    
    def _balanced_sampling_strategy(self):
        """平衡的采样策略 - 确保不同动作类型有均衡的样本数量"""
        samples = []
        
        # 按指令分组文件
        instruction_files = {'wave': [], 'welcome': []}
        for file_name in self.file_names:
            if 'wave' in file_name:
                instruction_files['wave'].append(file_name)
            elif 'welcome' in file_name:
                instruction_files['welcome'].append(file_name)
        
        # 对每个指令类型进行采样
        for instruction, files in instruction_files.items():
            instruction_samples = []
            
            for file_name in files:
                trajectory_path = os.path.join(self.data_dir, file_name)
                with open(trajectory_path, 'r') as f:
                    data = json.load(f)
                
                observations = data['observations']
                total_frames = len(observations)
                
                # 根据动作特性调整采样策略
                if instruction == 'wave':
                    # 挥手动作：周期性较长，使用较稀疏采样
                    # 目标：每个文件约60个样本
                    target_samples = 60
                    if total_frames > self.trajectory_length:
                        step = max(1, (total_frames - self.trajectory_length) // target_samples)
                        start_indices = list(range(0, total_frames - self.trajectory_length, step))
                    else:
                        start_indices = [0]
                elif instruction == 'welcome':
                    # 抱拳动作：时间较短，使用较密集采样
                    # 目标：每个文件约50个样本
                    target_samples = 50
                    if total_frames > self.trajectory_length:
                        step = max(1, (total_frames - self.trajectory_length) // target_samples)
                        start_indices = list(range(0, total_frames - self.trajectory_length, step))
                    else:
                        start_indices = [0]
                else:
                    # 默认策略
                    if total_frames > self.trajectory_length:
                        start_indices = list(range(0, total_frames - self.trajectory_length, 10))
                    else:
                        start_indices = [0]
                
                for start_idx in start_indices:
                    instruction_samples.append((instruction, file_name, start_idx))
            
            samples.extend(instruction_samples)
        
        return samples
    
    def __len__(self):
        return len(self.samples)
    
    def analyze_joint_importance(self, joint_positions):
        """分析关节重要性 - 基于变化幅度和范围的综合评估"""
        # 计算每个关节的标准差作为变化量指标
        joint_std = np.std(joint_positions, axis=0)
        
        # 计算每个关节的变化范围
        joint_range = np.max(joint_positions, axis=0) - np.min(joint_positions, axis=0)
        
        # 综合评估：变化量 + 变化范围
        joint_importance_raw = 0.7 * joint_std + 0.3 * joint_range
        
        # 使用softmax进行归一化，保持区分度
        if np.max(joint_importance_raw) > 0:
            # 使用指数函数增强重要关节的权重
            joint_importance = np.exp(joint_importance_raw * 2) / np.sum(np.exp(joint_importance_raw * 2))
        else:
            joint_importance = np.ones_like(joint_importance_raw) / len(joint_importance_raw)
        
        return joint_importance
    
    def sample_trajectory_segment(self, joint_positions, start_idx, trajectory_length):
        """采样轨迹段"""
        total_frames = len(joint_positions)
        
        if total_frames > trajectory_length:
            # 确保不超出范围
            end_idx = min(start_idx + trajectory_length, total_frames)
            segment = joint_positions[start_idx:end_idx]
            
            # 如果长度不够，填充最后一帧
            if len(segment) < trajectory_length:
                last_frame = segment[-1]
                padding = np.tile(last_frame, (trajectory_length - len(segment), 1))
                segment = np.vstack([segment, padding])
        else:
            # 数据不够长，使用整个轨迹并填充
            segment = joint_positions
            if len(segment) < trajectory_length:
                last_frame = segment[-1]
                padding = np.tile(last_frame, (trajectory_length - len(segment), 1))
                segment = np.vstack([segment, padding])
        
        return segment[:trajectory_length]
    
    def __getitem__(self, idx):
        instruction, file_name, start_idx = self.samples[idx]
        
        # 加载数据
        trajectory_path = os.path.join(self.data_dir, file_name)
        with open(trajectory_path, 'r') as f:
            data = json.load(f)
        
        # 提取关节数据
        observations = data['observations']
        joint_positions = np.array([obs['joint_pos'] for obs in observations])
        
        # 采样轨迹段
        trajectory = self.sample_trajectory_segment(joint_positions, start_idx, self.trajectory_length)
        
        # 获取起始状态
        start_state = trajectory[0]
        
        # 计算目标动作（绝对位置）
        target_actions = trajectory  # 直接使用绝对位置
        
        # 分析关节重要性
        joint_importance = self.analyze_joint_importance(trajectory)
        
        # 获取指令ID
        instruction_id = self.instruction_to_id[instruction]
        
        return {
            'start_state': start_state.astype(np.float32),
            'target_actions': target_actions.astype(np.float32),
            'instruction_id': np.array(instruction_id, dtype=np.int64),
            'joint_importance': joint_importance.astype(np.float32),
            'file_name': file_name,
            'start_idx': start_idx
        }

# ==============================================
# 3. 损失函数 - 关键关节专注的损失函数
# ==============================================

class KeyJointACTLoss(nn.Module):
    """关键关节专注的ACT损失函数"""
    
    def __init__(self, 
                 classification_weight=10.0, 
                 diversity_weight=5.0,
                 key_joint_weight=5.0,
                 stability_weight=0.01,
                 instruction_target_variances=None):  # 支持不同指令的目标变化量
        super().__init__()
        self.classification_weight = classification_weight
        self.diversity_weight = diversity_weight
        self.key_joint_weight = key_joint_weight
        self.stability_weight = stability_weight
        
        # 基于真实数据统计的目标变化量
        if instruction_target_variances is None:
            self.instruction_target_variances = {
                'wave': 0.108,  # 基于wave数据的平均变化量
                'welcome': 0.111  # 基于welcome数据的平均变化量
            }
        else:
            self.instruction_target_variances = instruction_target_variances
        
        # 指令ID到名称的映射
        self.id_to_instruction = {0: 'wave', 1: 'welcome'}
    
    def compute_key_joint_variance(self, actions, joint_importance, instruction_ids):
        """计算关键关节的变化量"""
        batch_size, seq_len, action_dim = actions.shape
        
        # 计算每个关节的变化量（方差）
        joint_variance = torch.var(actions, dim=1)  # [batch_size, action_dim]
        
        # 根据重要性加权
        weighted_variance = joint_variance * joint_importance
        
        # 计算每个样本的整体变化量（跨关节平均）
        overall_variance = torch.mean(weighted_variance, dim=1)  # [batch_size]
        
        return overall_variance
    
    def forward(self, predicted_actions, target_actions, instruction_logits, instruction_ids, 
                joint_importance, key_joint_actions):
        """计算损失 - 极简版本，确保数值稳定"""
        
        batch_size = predicted_actions.size(0)
        
        # 1. 基础动作预测损失
        action_loss = nn.functional.mse_loss(predicted_actions, target_actions)
        
        # 2. 指令分类损失
        classification_loss = nn.functional.cross_entropy(instruction_logits, instruction_ids)
        
        # 3. 关键关节专注损失 - 极简版本
        # 计算每个关节的方差
        joint_variance = torch.var(predicted_actions, dim=1)  # [batch_size, action_dim]
        overall_variance = torch.mean(joint_variance, dim=1)  # [batch_size]
        
        # 使用固定的目标变化量，避免复杂数值计算
        target_variance = 0.1
        key_joint_loss = torch.mean(torch.abs(overall_variance - target_variance))
        
        # 4. 时序稳定性损失 - 极简版本
        if predicted_actions.shape[1] > 1:
            action_diff = torch.diff(predicted_actions, dim=1)
            stability_loss = torch.mean(torch.abs(action_diff))
        else:
            stability_loss = torch.tensor(0.0, device=predicted_actions.device)
        
        # 5. 指令模式多样性损失 - 极简版本
        diversity_loss = torch.tensor(0.0, device=predicted_actions.device)
        unique_instructions = torch.unique(instruction_ids)
        if len(unique_instructions) > 1:
            pattern_means = []
            for instr_id in unique_instructions:
                mask = instruction_ids == instr_id
                if mask.any():
                    pattern_mean = torch.mean(predicted_actions[mask], dim=(0, 1))
                    pattern_means.append(pattern_mean)
            
            if len(pattern_means) > 1:
                pattern_means = torch.stack(pattern_means)
                pattern_diff_matrix = torch.pdist(pattern_means, p=2)
                diversity_loss = torch.mean(torch.relu(0.5 - pattern_diff_matrix))
        
        # 综合损失 - 极简版本
        losses = [
            action_loss,
            self.classification_weight * classification_loss,
            self.key_joint_weight * key_joint_loss,
            self.diversity_weight * diversity_loss,
            self.stability_weight * stability_loss
        ]
        
        # 检查每个损失项是否有效
        valid_losses = []
        for i, loss in enumerate(losses):
            if torch.isnan(loss) or torch.isinf(loss):
                print(f"警告: 损失项{i}数值异常: {loss.item()}, 替换为0")
                valid_losses.append(torch.tensor(0.0, device=loss.device))
            else:
                valid_losses.append(loss)
        
        total_loss = torch.stack(valid_losses).sum()
        
        return {
            'total_loss': total_loss,
            'action_loss': action_loss,
            'classification_loss': classification_loss,
            'key_joint_loss': key_joint_loss,
            'diversity_loss': diversity_loss,
            'stability_loss': stability_loss,
            'key_joint_variance': torch.mean(overall_variance)
        }

# ==============================================
# 4. 训练函数
# ==============================================

def train_key_joint_act_model():
    """训练关键关节专注的ACT模型"""
    print("开始训练关键关节专注的ACT模型...")
    print("核心特性：自动识别关键关节，专注于变化大的关节学习")
    print("预测后32步，使用Transformer时序模型")
    
    # 模型配置 - 使用更保守的配置
    model_config = {
        'state_dim': 26,
        'action_dim': 26,
        'num_instructions': 2,
        'hidden_dim': 256,
        'trajectory_length': 32,  # 预测后32步，简化学习任务
        'dropout': 0.2,  # 降低dropout，防止早期训练不稳定
        'key_joints_per_instruction': 8,  # 每个指令重点关注8个关节
        'predict_differences': False,  # 直接预测绝对位置
        'signal_amplification': 1.0  # 不使用信号放大
    }
    
    # 训练配置 - 平衡性能和稳定性
    training_config = {
        'learning_rate': 1e-4,  # 适中的学习率
        'weight_decay': 1e-4,  # 适中的权重衰减
        'batch_size': 64,  # 恢复较大的batch size以提高GPU利用率
        'epochs': 2000,
        'classification_weight': 1.0,  # 降低分类权重
        'diversity_weight': 0.5,  # 降低多样性权重
        'key_joint_weight': 0.5,  # 降低关键关节权重
        'stability_weight': 0.05  # 降低稳定性权重
    }
    
    # 数据准备
    data_dir = '/root/kuavo_ws/src/vla/trajectories'
    file_names = [f'wave_{i:03d}.json' for i in range(1, 9)] + [f'welcome_{i:03d}.json' for i in range(1, 9)]
    
    print(f"使用数据文件: {len(file_names)} 个")
    print(f"模型配置: {model_config}")
    print(f"训练配置: {training_config}")
    
    # 数据集
    dataset = KeyJointDataset(
        data_dir, file_names, 
        trajectory_length=model_config['trajectory_length']
    )
    
    # 创建模型和数据加载
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"使用设备: {device}")
    
    # 数据集划分
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
    
    # 优化数据加载以提高GPU利用率
    train_loader = DataLoader(
        train_dataset, 
        batch_size=training_config['batch_size'], 
        shuffle=True,
        num_workers=4,  # 使用多个工作进程加载数据
        pin_memory=True if device.type == 'cuda' else False,  # 固定内存加速GPU传输
        persistent_workers=True  # 保持工作进程活跃
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=training_config['batch_size'], 
        shuffle=False,
        num_workers=2,
        pin_memory=True if device.type == 'cuda' else False,
        persistent_workers=True
    )
    
    print(f"训练集: {len(train_dataset)}, 验证集: {len(val_dataset)}")
    print(f"数据加载优化: num_workers=4, pin_memory={device.type == 'cuda'}")
    
    # 创建模型 - 使用改进的版本
    model = ImprovedKeyJointACTGenerator(model_config).to(device)
    
    # 启用自动混合精度训练提高GPU性能
    scaler = torch.amp.GradScaler('cuda', init_scale=65536.0, growth_factor=2.0, backoff_factor=0.5, growth_interval=2000) if device.type == 'cuda' else None
    print(f"自动混合精度: {'启用' if scaler else '禁用'}")
    if scaler:
        print(f"  初始缩放因子: {scaler.get_scale()}")
    
    # 计算参数数量
    total_params = sum(p.numel() for p in model.parameters())
    print(f"模型参数数量: {total_params:,}")
    
    # 损失函数
    loss_fn = KeyJointACTLoss(
        classification_weight=training_config['classification_weight'],
        diversity_weight=training_config['diversity_weight'],
        key_joint_weight=training_config['key_joint_weight'],
        stability_weight=training_config['stability_weight']
    )
    
    # 优化器 - 使用更稳定的优化器，启用GPU优化
    optimizer = optim.AdamW(
        model.parameters(), 
        lr=training_config['learning_rate'],
        weight_decay=training_config['weight_decay'],
        betas=(0.9, 0.999),
        fused=True  # 使用融合优化器提高GPU性能
    )
    
    # 学习率调度器 - 使用更保守的学习率调度
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, 
        mode='min', 
        factor=0.8,  # 更温和的降低
        patience=100,  # 更长的耐心
        verbose=True,
        min_lr=1e-7  # 更低的最小学习率
    )
    
    # 创建保存目录
    save_dir = './checkpoints/improved_act_model_v1'
    os.makedirs(save_dir, exist_ok=True)
    
    print(f"开始训练...")
    
    # 初始化质量监控系统
    quality_validator = ActionQualityValidator()
    quality_monitor = TrainingQualityMonitor(quality_validator)
    print("质量监控系统已初始化")
    
    # 训练循环
    best_val_loss = float('inf')
    patience = 150  # 增加耐心值
    patience_counter = 0
    
    # 用于跟踪训练稳定性
    val_loss_history = []
    
    # 启用cuDNN benchmark模式提高GPU性能
    if device.type == 'cuda':
        torch.backends.cudnn.benchmark = True
        print("启用cuDNN benchmark模式")
    
    for epoch in range(training_config['epochs']):
        # 训练阶段
        model.train()
        train_losses = []
        train_action_losses = []
        train_classification_losses = []
        train_key_joint_losses = []
        train_diversity_losses = []
        train_stability_losses = []
        train_accuracies = []
        train_key_joint_variances = []
        
        for batch in train_loader:
            start_states = batch['start_state'].to(device)
            target_actions = batch['target_actions'].to(device)
            instruction_ids = batch['instruction_id'].to(device)
            
            # 使用自动混合精度训练
            if scaler:
                with torch.amp.autocast('cuda'):
                    # 前向传播
                    timesteps = torch.arange(0, 32, dtype=torch.float32).unsqueeze(0).expand(start_states.shape[0], -1).to(start_states.device)
                    model_outputs = model(start_states, instruction_ids, timesteps)
                    predicted_actions = model_outputs['predictions']
                    instruction_logits = model_outputs['classification_logits']
                    joint_importance = model_outputs['joint_importance']
                    key_joint_actions = model_outputs['key_joint_predictions']
                    
                    # 计算损失
                    loss_dict = loss_fn(
                        predicted_actions, target_actions, instruction_logits, instruction_ids,
                        joint_importance, key_joint_actions
                    )
                
                # 质量监控 - 每10个batch监控一次
                if len(train_losses) % 10 == 0:
                    batch_quality = quality_monitor.monitor_batch(
                        predicted_actions, target_actions, instruction_ids
                    )
                    current_quality = batch_quality.get('overall_quality', 0.0)
                
                # 简单的反向传播
                total_loss = loss_dict['total_loss']
                optimizer.zero_grad()
                scaler.scale(total_loss).backward()
                
                # 梯度裁剪 - 必须在unscale之前进行
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)
                
                scaler.step(optimizer)
                scaler.update()
            else:
                # CPU模式
                # 前向传播
                timesteps = torch.arange(0, 32, dtype=torch.float32).unsqueeze(0).expand(start_states.shape[0], -1).to(start_states.device)
                model_outputs = model(start_states, instruction_ids, timesteps)
                predicted_actions = model_outputs['predictions']
                instruction_logits = model_outputs['classification_logits']
                joint_importance = model_outputs['joint_importance']
                key_joint_actions = model_outputs['key_joint_predictions']
                
                # 计算损失
                loss_dict = loss_fn(
                    predicted_actions, target_actions, instruction_logits, instruction_ids,
                    joint_importance, key_joint_actions
                )
                
                # 质量监控 - 每10个batch监控一次
                if len(train_losses) % 10 == 0:
                    batch_quality = quality_monitor.monitor_batch(
                        predicted_actions, target_actions, instruction_ids
                    )
                    current_quality = batch_quality.get('overall_quality', 0.0)
                
                # 反向传播
                optimizer.zero_grad()
                loss_dict['total_loss'].backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)
                optimizer.step()
            
            # 记录损失
            total_loss = loss_dict['total_loss'].item()
            train_losses.append(total_loss)
            train_action_losses.append(loss_dict['action_loss'].item())
            train_classification_losses.append(loss_dict['classification_loss'].item())
            train_key_joint_losses.append(loss_dict['key_joint_loss'].item())
            train_diversity_losses.append(loss_dict['diversity_loss'].item())
            train_stability_losses.append(loss_dict['stability_loss'].item())
            train_key_joint_variances.append(loss_dict['key_joint_variance'].item())
            
            # 计算分类准确率
            predicted_ids = torch.argmax(instruction_logits, dim=1)
            accuracy = (predicted_ids == instruction_ids).float().mean().item()
            train_accuracies.append(accuracy)
        
        # 验证阶段
        model.eval()
        val_losses = []
        val_action_losses = []
        val_classification_losses = []
        val_key_joint_losses = []
        val_diversity_losses = []
        val_stability_losses = []
        val_accuracies = []
        val_key_joint_variances = []
        
        with torch.no_grad():
            for batch in val_loader:
                start_states = batch['start_state'].to(device)
                target_actions = batch['target_actions'].to(device)
                instruction_ids = batch['instruction_id'].to(device)
                
                timesteps = torch.arange(0, 32, dtype=torch.float32).unsqueeze(0).expand(start_states.shape[0], -1).to(start_states.device)
                model_outputs = model(start_states, instruction_ids, timesteps)
                predicted_actions = model_outputs['predictions']
                instruction_logits = model_outputs['classification_logits']
                joint_importance = model_outputs['joint_importance']
                key_joint_actions = model_outputs['key_joint_predictions']
                
                loss_dict = loss_fn(
                    predicted_actions, target_actions, instruction_logits, instruction_ids,
                    joint_importance, key_joint_actions
                )
                
                # 检查数值稳定性
                val_total_loss = loss_dict['total_loss'].item()
                if not torch.isnan(loss_dict['total_loss']) and not np.isnan(val_total_loss) and not np.isinf(val_total_loss):
                    val_losses.append(val_total_loss)
                    val_action_losses.append(loss_dict['action_loss'].item())
                    val_classification_losses.append(loss_dict['classification_loss'].item())
                    val_key_joint_losses.append(loss_dict['key_joint_loss'].item())
                    val_diversity_losses.append(loss_dict['diversity_loss'].item())
                    val_stability_losses.append(loss_dict['stability_loss'].item())
                    val_key_joint_variances.append(loss_dict['key_joint_variance'].item())
                    
                    # 计算分类准确率
                    predicted_ids = torch.argmax(instruction_logits, dim=1)
                    accuracy = (predicted_ids == instruction_ids).float().mean().item()
                    val_accuracies.append(accuracy)
        
        # 计算平均损失 - 添加空列表检查
        avg_train_loss = np.mean(train_losses) if train_losses else float('nan')
        avg_train_action = np.mean(train_action_losses) if train_action_losses else float('nan')
        avg_train_classification = np.mean(train_classification_losses) if train_classification_losses else float('nan')
        avg_train_key_joint = np.mean(train_key_joint_losses) if train_key_joint_losses else float('nan')
        avg_train_diversity = np.mean(train_diversity_losses) if train_diversity_losses else float('nan')
        avg_train_stability = np.mean(train_stability_losses) if train_stability_losses else float('nan')
        avg_train_accuracy = np.mean(train_accuracies) if train_accuracies else float('nan')
        avg_train_key_variance = np.mean(train_key_joint_variances) if train_key_joint_variances else float('nan')
        
        avg_val_loss = np.mean(val_losses) if val_losses else float('nan')
        avg_val_action = np.mean(val_action_losses) if val_action_losses else float('nan')
        avg_val_classification = np.mean(val_classification_losses) if val_classification_losses else float('nan')
        avg_val_key_joint = np.mean(val_key_joint_losses) if val_key_joint_losses else float('nan')
        avg_val_diversity = np.mean(val_diversity_losses) if val_diversity_losses else float('nan')
        avg_val_stability = np.mean(val_stability_losses) if val_stability_losses else float('nan')
        avg_val_accuracy = np.mean(val_accuracies) if val_accuracies else float('nan')
        avg_val_key_variance = np.mean(val_key_joint_variances) if val_key_joint_variances else float('nan')
        
        # 更新学习率
        scheduler.step(avg_val_loss)
        
        # 记录验证损失历史
        val_loss_history.append(avg_val_loss)
        
        # 质量监控 - 每个epoch结束后生成质量报告
        epoch_quality = quality_monitor.monitor_epoch(epoch)
        
        # 打印进度 - 每20个epoch打印一次
        if epoch % 20 == 0:
            quality_info = f"Quality: {epoch_quality.get('overall_quality', 0.0):.3f}" if epoch_quality else ""
            print(f"Epoch {epoch+1}/{training_config['epochs']} - "
                  f"Train Total: {avg_train_loss:.4f}, Val Total: {avg_val_loss:.4f}, "
                  f"Val Action: {avg_val_action:.4f}, Val Class: {avg_val_classification:.4f}, "
                  f"Val KeyJoint: {avg_val_key_joint:.4f}, Val Div: {avg_val_diversity:.4f}, "
                  f"Val Stability: {avg_val_stability:.4f}, Acc: {avg_val_accuracy:.3f}, "
                  f"KeyVar: {avg_val_key_variance:.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}, "
                  f"{quality_info}")
            
            # 每100个epoch打印详细质量报告
            if epoch % 100 == 0 and epoch > 0:
                print("\n" + "="*50)
                print("详细质量报告:")
                print(quality_monitor.get_quality_report())
                print("="*50 + "\n")
        
        # 保存最佳模型 - 只有当验证损失真正改善时才保存
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            
            # 计算数据集统计信息
            dataset_stats = {
                'state_mean': np.zeros(26),
                'state_std': np.ones(26),
                'action_mean': np.zeros(26),
                'action_std': np.ones(26)
            }
            
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'model_config': model_config,
                'training_config': training_config,
                'best_val_loss': best_val_loss,
                'val_accuracy': avg_val_accuracy,
                'val_key_joint_variance': avg_val_key_variance,
                'norm_stats': dataset_stats
            }
            
            torch.save(checkpoint, os.path.join(save_dir, 'best_model.pth'))
            print(f"  保存最佳模型 - Val Loss: {best_val_loss:.4f}, Acc: {avg_val_accuracy:.3f}")
        else:
            patience_counter += 1
        
        # 早停 - 只有在连续多个epoch都没有改善时才停止
        if patience_counter >= patience and len(val_loss_history) > 100:
            # 检查最近的趋势是否真的稳定
            recent_losses = val_loss_history[-50:]
            if np.mean(recent_losses) > np.mean(val_loss_history[-100:-50]):
                print(f"早停: {patience} 轮验证损失没有改善，且呈上升趋势")
                break
    
    print("训练完成!")
    print(f"最佳验证损失: {best_val_loss:.4f}")
    print(f"模型参数数量: {total_params:,}")
    
    # 保存最终质量报告
    final_quality_report = quality_monitor.get_quality_report()
    print("\n" + "="*50)
    print("最终质量报告:")
    print(final_quality_report)
    print("="*50)
    
    # 保存质量历史数据
    quality_monitor.save_quality_history(os.path.join(save_dir, 'quality_history.json'))
    
    return model, model_config, training_config

# ==============================================
# 5. 主函数
# ==============================================

def main():
    """主训练函数"""
    print("=" * 60)
    print("VLA项目关键关节专注ACT训练")
    print("=" * 60)
    print("核心特性：")
    print("1. 自动识别每个指令的关键关节")
    print("2. 专注于变化大的关节学习")
    print("3. 使用Transformer时序模型预测后32步")
    print("4. 稳定的训练策略，避免早期震荡")
    print("=" * 60)
    
    try:
        model, model_config, training_config = train_key_joint_act_model()
        
        print("\n" + "=" * 60)
        print("训练完成！")
        print("=" * 60)
        print(f"模型配置: {model_config}")
        print(f"训练配置: {training_config}")
        print(f"模型已保存到: ./checkpoints/key_joint_act_model_v1/best_model.pth")
        print("\n使用方法：")
        print("python simple_act_train.py")
        
    except Exception as e:
        print(f"训练过程中出现错误: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

class JointSpecializedPredictor(nn.Module):
    """
    关节专用预测器 - 符合CRITICAL PRINCIPLE
    第一层：指令分类器
    第二层：每个指令专用的关节预测器，专注于特定关节
    """
    
    def __init__(self, base_model, action_dim=26, hidden_dim=256, chunk_length=100, 
                 instruction_vocab_size=2, condition_dim=256):
        super().__init__()
        self.base_model = base_model
        self.action_dim = action_dim
        self.hidden_dim = hidden_dim
        self.chunk_length = chunk_length
        self.instruction_vocab_size = instruction_vocab_size
        self.condition_dim = condition_dim
        
        # 第一层：指令分类器 - 必须有
        self.instruction_classifier = nn.Sequential(
            nn.Linear(condition_dim, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, instruction_vocab_size)
        )
        
        # 状态编码器
        self.state_encoder = nn.Sequential(
            nn.Linear(26, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, hidden_dim)
        )
        
        # 条件编码器
        self.condition_encoder = nn.Sequential(
            nn.Linear(condition_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, hidden_dim)
        )
        
        # 指令嵌入
        self.instruction_embedding = nn.Embedding(instruction_vocab_size, 32)
        
        # 时序编码器
        self.temporal_input_size = hidden_dim * 2 + 32 + 1  # state + condition + instruction + time
        self.temporal_encoder = nn.LSTM(
            input_size=self.temporal_input_size,
            hidden_size=hidden_dim,
            num_layers=3,
            batch_first=True,
            dropout=0.3,
            bidirectional=False
        )
        
        # 第二层：每个指令专用的动作预测器
        # wave指令专用 - 专注于wave动作的关键关节
        self.wave_predictor = nn.Sequential(
            nn.Linear(hidden_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, action_dim)
        )
        
        # welcome指令专用 - 专注于welcome动作的关键关节
        self.welcome_predictor = nn.Sequential(
            nn.Linear(hidden_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, action_dim)
        )
        
        # 关节重要性权重 - 学习每个指令对哪些关节更重要
        self.wave_joint_weights = nn.Parameter(torch.ones(action_dim) / action_dim)
        self.welcome_joint_weights = nn.Parameter(torch.ones(action_dim) / action_dim)
        
        # 损失权重
        self.classification_weight = 10.0
        self.diversity_weight = 5.0
        
    def forward(self, instruction_ids: torch.Tensor, state: torch.Tensor) -> Dict[str, torch.Tensor]:
        """关节专用的前向传播 - 符合CRITICAL PRINCIPLE"""
        
        # 获取基础模型的条件编码
        base_outputs = self.base_model(
            instruction_ids=instruction_ids,
            state=state,
            visual_features=None,
            target_actions=None
        )
        condition = base_outputs['condition']  # [batch_size, condition_dim]
        
        batch_size = condition.size(0)
        device = condition.device
        
        # 第一层：指令分类
        instruction_logits = self.instruction_classifier(condition)  # [batch_size, vocab_size]
        
        # 状态编码
        state_encoded = self.state_encoder(state)  # [batch_size, hidden_dim]
        condition_encoded = self.condition_encoder(condition)  # [batch_size, hidden_dim]
        
        # 指令嵌入
        instruction_emb = self.instruction_embedding(instruction_ids)  # [batch_size, 32]
        
        # 准备时序输入
        state_expanded = state_encoded.unsqueeze(1).expand(-1, self.chunk_length, -1)
        condition_expanded = condition_encoded.unsqueeze(1).expand(-1, self.chunk_length, -1)
        instruction_expanded = instruction_emb.unsqueeze(1).expand(-1, self.chunk_length, -1)
        
        # 添加时间编码
        time_encoding = torch.arange(self.chunk_length, dtype=torch.float32, device=device)
        time_encoding = time_encoding.unsqueeze(0).unsqueeze(-1) / self.chunk_length
        time_encoding = time_encoding.expand(batch_size, -1, 1)
        
        # 组合时序输入
        temporal_input = torch.cat([state_expanded, condition_expanded, instruction_expanded, time_encoding], dim=-1)
        
        # 通过时序编码器
        temporal_output, _ = self.temporal_encoder(temporal_input)  # [batch_size, seq_len, hidden_dim]
        
        # 为每个指令使用专用预测器
        wave_actions = self._predict_for_instruction(temporal_output, 0)  # wave指令
        welcome_actions = self._predict_for_instruction(temporal_output, 1)  # welcome指令
        
        # 根据真实指令选择对应的动作
        predicted_changes = torch.zeros(batch_size, self.chunk_length, self.action_dim, device=device)
        for i in range(batch_size):
            if instruction_ids[i] == 0:  # wave
                predicted_changes[i] = wave_actions[i]
            else:  # welcome
                predicted_changes[i] = welcome_actions[i]
        
        # 第一个时间步的变化量应该为0
        predicted_changes[:, 0, :] = 0
        
        return {
            'predicted_changes': predicted_changes,
            'instruction_logits': instruction_logits,
            'condition': condition,
            'wave_actions': wave_actions,
            'welcome_actions': welcome_actions,
            'wave_joint_weights': torch.softmax(self.wave_joint_weights, dim=0),
            'welcome_joint_weights': torch.softmax(self.welcome_joint_weights, dim=0)
        }
    
    def _predict_for_instruction(self, temporal_output: torch.Tensor, instruction_id: int) -> torch.Tensor:
        """为特定指令预测动作序列"""
        batch_size, seq_len, hidden_dim = temporal_output.shape
        
        # 逐步预测每个时间步
        predicted_changes = []
        for t in range(seq_len):
            hidden_state = temporal_output[:, t, :]  # [batch_size, hidden_dim]
            
            if instruction_id == 0:  # wave
                action_change = self.wave_predictor(hidden_state)
            else:  # welcome
                action_change = self.welcome_predictor(hidden_state)
            
            predicted_changes.append(action_change)
        
        return torch.stack(predicted_changes, dim=1)  # [batch_size, seq_len, action_dim]
    
    def compute_loss(self, predicted_changes: torch.Tensor, target_actions: torch.Tensor, 
                    instruction_logits: torch.Tensor, instruction_ids: torch.Tensor,
                    wave_actions: torch.Tensor, welcome_actions: torch.Tensor,
                    wave_joint_weights: torch.Tensor, welcome_joint_weights: torch.Tensor) -> Dict[str, torch.Tensor]:
        """关节专用的损失函数 - 强制不同指令关注不同关节"""
        
        # 1. 动作预测MSE损失
        action_loss = nn.functional.mse_loss(predicted_changes, target_actions)
        
        # 2. 指令分类损失
        classification_loss = nn.functional.cross_entropy(instruction_logits, instruction_ids)
        
        # 3. 指令多样性损失 - 强制不同指令产生不同动作
        wave_mean = torch.mean(wave_actions, dim=(0, 1))
        welcome_mean = torch.mean(welcome_actions, dim=(0, 1))
        pattern_diff = torch.norm(wave_mean - welcome_mean, p=2)
        diversity_loss = torch.relu(1.0 - pattern_diff)
        
        # 4. 关节专用损失 - 强制每个指令专注于不同的关节
        # 计算每个关节的重要性差异 - 使用更强的约束
        joint_weight_diff = torch.norm(wave_joint_weights - welcome_joint_weights, p=1)
        specialization_loss = torch.relu(1.0 - joint_weight_diff)  # 增加目标差异
        
        # 添加关节权重熵损失 - 防止所有关节权重相同
        wave_entropy = -torch.sum(wave_joint_weights * torch.log(wave_joint_weights + 1e-8))
        welcome_entropy = -torch.sum(welcome_joint_weights * torch.log(welcome_joint_weights + 1e-8))
        entropy_loss = (wave_entropy + welcome_entropy) / 2.0  # 鼓励专业化
        
        # 5. 时间动态损失 - 防止输出恒定值
        time_variance = torch.var(predicted_changes, dim=1).mean()
        dynamic_loss = torch.relu(0.001 - time_variance)
        
        # 综合损失
        total_loss = (action_loss + 
                     self.classification_weight * classification_loss + 
                     self.diversity_weight * diversity_loss + 
                     2.0 * specialization_loss + 
                     0.5 * entropy_loss +  # 添加熵损失
                     0.01 * dynamic_loss)
        
        return {
            'total_loss': total_loss,
            'action_loss': action_loss,
            'classification_loss': classification_loss,
            'diversity_loss': diversity_loss,
            'specialization_loss': specialization_loss,
            'entropy_loss': entropy_loss,
            'dynamic_loss': dynamic_loss,
            'pattern_diff': pattern_diff,
            'joint_weight_diff': joint_weight_diff,
            'time_variance': time_variance
        }

class AdaptiveFrameSkipDataset(Dataset):
    """均匀帧选择数据集 - 避免信号放大"""
    
    def __init__(self, data_dir: str, file_names: list, chunk_length: int = 100):
        self.data_dir = data_dir
        self.file_names = file_names
        self.chunk_length = chunk_length
        
        # 指令映射
        self.instruction_to_id = {'wave': 0, 'welcome': 1}
        
        # 创建样本列表
        self.samples = []
        for file_name in file_names:
            if 'wave' in file_name:
                instruction = 'wave'
            elif 'welcome' in file_name:
                instruction = 'welcome'
            else:
                continue
            
            # 加载数据
            trajectory_path = os.path.join(self.data_dir, file_name)
            with open(trajectory_path, 'r') as f:
                data = json.load(f)
            
            observations = data['observations']
            total_frames = len(observations)
            
            # 创建多个起始点
            max_start = total_frames - self.chunk_length
            if max_start > 0:
                start_indices = list(range(0, max_start, 20))
            else:
                start_indices = [0]
            
            for start_idx in start_indices:
                self.samples.append((instruction, file_name, start_idx))
    
    def __len__(self):
        return len(self.samples)
    
    def smart_frame_selection(self, joint_positions, start_idx, chunk_length):
        """均匀帧选择 - 避免信号放大，保持数据统计特性"""
        # 使用固定步长采样，避免智能选择带来的信号放大
        total_frames = len(joint_positions)
        
        # 计算固定步长
        if total_frames > chunk_length:
            step = (total_frames - 1) / (chunk_length - 1)
            selected_indices = []
            for i in range(chunk_length):
                idx = int(start_idx + i * step)
                idx = min(idx, total_frames - 1)
                selected_indices.append(idx)
        else:
            # 如果数据不够长，重复最后一帧
            selected_indices = list(range(min(start_idx + chunk_length, total_frames)))
            while len(selected_indices) < chunk_length:
                selected_indices.append(selected_indices[-1])
        
        return selected_indices[:chunk_length]
    
    def __getitem__(self, idx):
        instruction, file_name, start_idx = self.samples[idx]
        
        # 加载数据
        trajectory_path = os.path.join(self.data_dir, file_name)
        with open(trajectory_path, 'r') as f:
            data = json.load(f)
        
        # 提取关节数据
        observations = data['observations']
        joint_positions = np.array([obs['joint_pos'] for obs in observations])
        
        # 智能帧选择
        selected_indices = self.smart_frame_selection(joint_positions, start_idx, self.chunk_length)
        trajectory = joint_positions[selected_indices]
        
        # 获取起始状态
        start_state = trajectory[0]
        
        # 计算差分动作
        target_actions = np.diff(trajectory, axis=0)
        # 填充最后一个时间步
        last_diff = target_actions[-1:] if len(target_actions) > 0 else np.zeros((1, trajectory.shape[1]))
        target_actions = np.vstack([target_actions, last_diff])
        
        # 获取指令ID
        instruction_id = self.instruction_to_id[instruction]
        
        return {
            'start_state': start_state.astype(np.float32),
            'target_actions': target_actions.astype(np.float32),
            'instruction_id': np.array(instruction_id, dtype=np.int64),
            'file_name': file_name,
            'start_idx': start_idx
        }

def train_joint_specialized_model():
    """训练关节专用模型 - 符合CRITICAL PRINCIPLE"""
    print("开始训练关节专用模型...")
    
    # 合理容量模型配置
    model_config = {
        'action_dim': 26,
        'chunk_length': 100,
        'state_dim': 60,
        'visual_feature_dim': 512,
        'instruction_vocab_size': 2,
        'instruction_embed_dim': 64,
        'condition_dim': 256,  # 适中的条件维度
        'hidden_dim': 256,     # 适中的隐藏维度
        'num_heads': 4,        # 适中的注意力头数
        'num_layers': 3        # 适中的层数
    }
    
    training_config = {
        'learning_rate': 1e-3,
        'weight_decay': 1e-4,
        'batch_size': 8,      # 更小的batch size
        'epochs': 1000,
        'change_threshold': 0.001,
        'merge_window_size': 5
    }
    
    # 数据准备
    data_dir = '/root/kuavo_ws/src/vla/trajectories'
    file_names = [f'wave_{i:03d}.json' for i in range(1, 9)] + [f'welcome_{i:03d}.json' for i in range(1, 9)]
    
    print(f"使用数据文件: {len(file_names)} 个")
    print(f"核心改进:")
    print(f"  - 关节专用模型: {model_config['hidden_dim']}隐藏维度")
    print(f"  - 符合CRITICAL PRINCIPLE: 指令分类 + 动作预测")
    print(f"  - 关节专用预测器：不同指令专注不同关节")
    print(f"  - 关节重要性权重学习")
    print(f"  - 模型预计大小: 10-30MB")
    
    # 数据集
    dataset = AdaptiveFrameSkipDataset(
        data_dir, file_names, 
        chunk_length=model_config['chunk_length']
    )
    
    # 数据集划分
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
    
    train_loader = DataLoader(train_dataset, batch_size=training_config['batch_size'], shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=training_config['batch_size'], shuffle=False)
    
    print(f"训练集: {len(train_dataset)}, 验证集: {len(val_dataset)}")
    
    # 创建关节专用模型
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    base_model = create_direct_action_model(model_config).to(device)
    model = JointSpecializedPredictor(
        base_model=base_model,
        action_dim=model_config['action_dim'],
        hidden_dim=model_config['hidden_dim'],
        chunk_length=model_config['chunk_length'],
        instruction_vocab_size=model_config['instruction_vocab_size'],
        condition_dim=model_config['condition_dim']
    ).to(device)
    
    # 计算参数数量
    total_params = sum(p.numel() for p in model.parameters())
    print(f"模型参数数量: {total_params:,}")
    estimated_size_mb = total_params * 4 / (1024 * 1024)  # 估算模型大小(MB)
    print(f"估算模型大小: {estimated_size_mb:.1f}MB")
    
    # 优化器 - 使用AdamW提高训练稳定性
    optimizer = optim.AdamW(
        model.parameters(), 
        lr=training_config['learning_rate'],
        weight_decay=training_config['weight_decay']
    )
    
    # 学习率调度器
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, 
        mode='min', 
        factor=0.5,
        patience=30,
        verbose=True
    )
    
    # 创建保存目录
    save_dir = './checkpoints/enhanced_state_dependent_model_v1'
    os.makedirs(save_dir, exist_ok=True)
    
    print(f"开始训练关节专用模型...")
    
    # 训练循环
    best_val_loss = float('inf')
    patience = 100
    patience_counter = 0
    
    for epoch in range(training_config['epochs']):
        # 训练阶段
        model.train()
        train_losses = []
        train_action_losses = []
        train_classification_losses = []
        train_diversity_losses = []
        train_specialization_losses = []
        train_entropy_losses = []
        train_dynamic_losses = []
        train_accuracies = []
        train_pattern_diffs = []
        
        for batch in train_loader:
            start_states = batch['start_state'].to(device)
            target_actions = batch['target_actions'].to(device)
            instruction_ids = batch['instruction_id'].to(device)
            
            # 前向传播
            outputs = model(instruction_ids, start_states)
            predicted_changes = outputs['predicted_changes']
            instruction_logits = outputs['instruction_logits']
            wave_actions = outputs['wave_actions']
            welcome_actions = outputs['welcome_actions']
            wave_joint_weights = outputs['wave_joint_weights']
            welcome_joint_weights = outputs['welcome_joint_weights']
            
            # 计算关节专用损失
            loss_dict = model.compute_loss(
                predicted_changes, target_actions, instruction_logits, instruction_ids,
                wave_actions, welcome_actions, wave_joint_weights, welcome_joint_weights
            )
            
            # 反向传播
            optimizer.zero_grad()
            loss_dict['total_loss'].backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            
            # 记录损失
            train_losses.append(loss_dict['total_loss'].item())
            train_action_losses.append(loss_dict['action_loss'].item())
            train_classification_losses.append(loss_dict['classification_loss'].item())
            train_diversity_losses.append(loss_dict['diversity_loss'].item())
            train_specialization_losses.append(loss_dict['specialization_loss'].item())
            train_entropy_losses.append(loss_dict['entropy_loss'].item())
            train_dynamic_losses.append(loss_dict['dynamic_loss'].item())
            train_pattern_diffs.append(loss_dict['pattern_diff'].item())
            
            # 计算分类准确率
            predicted_ids = torch.argmax(instruction_logits, dim=1)
            accuracy = (predicted_ids == instruction_ids).float().mean().item()
            train_accuracies.append(accuracy)
        
        # 验证阶段
        model.eval()
        val_losses = []
        val_action_losses = []
        val_classification_losses = []
        val_diversity_losses = []
        val_specialization_losses = []
        val_entropy_losses = []
        val_dynamic_losses = []
        val_accuracies = []
        val_pattern_diffs = []
        
        with torch.no_grad():
            for batch in val_loader:
                start_states = batch['start_state'].to(device)
                target_actions = batch['target_actions'].to(device)
                instruction_ids = batch['instruction_id'].to(device)
                
                outputs = model(instruction_ids, start_states)
                predicted_changes = outputs['predicted_changes']
                instruction_logits = outputs['instruction_logits']
                wave_actions = outputs['wave_actions']
                welcome_actions = outputs['welcome_actions']
                wave_joint_weights = outputs['wave_joint_weights']
                welcome_joint_weights = outputs['welcome_joint_weights']
                
                # 计算关节专用损失
                loss_dict = model.compute_loss(
                    predicted_changes, target_actions, instruction_logits, instruction_ids,
                    wave_actions, welcome_actions, wave_joint_weights, welcome_joint_weights
                )
                
                val_losses.append(loss_dict['total_loss'].item())
                val_action_losses.append(loss_dict['action_loss'].item())
                val_classification_losses.append(loss_dict['classification_loss'].item())
                val_diversity_losses.append(loss_dict['diversity_loss'].item())
                val_specialization_losses.append(loss_dict['specialization_loss'].item())
                val_entropy_losses.append(loss_dict['entropy_loss'].item())
                val_dynamic_losses.append(loss_dict['dynamic_loss'].item())
                val_pattern_diffs.append(loss_dict['pattern_diff'].item())
                
                # 计算分类准确率
                predicted_ids = torch.argmax(instruction_logits, dim=1)
                accuracy = (predicted_ids == instruction_ids).float().mean().item()
                val_accuracies.append(accuracy)
        
        # 计算平均损失
        avg_train_loss = np.mean(train_losses)
        avg_train_action = np.mean(train_action_losses)
        avg_train_classification = np.mean(train_classification_losses)
        avg_train_diversity = np.mean(train_diversity_losses)
        avg_train_specialization = np.mean(train_specialization_losses)
        avg_train_entropy = np.mean(train_entropy_losses)
        avg_train_dynamic = np.mean(train_dynamic_losses)
        avg_train_accuracy = np.mean(train_accuracies)
        avg_train_pattern_diff = np.mean(train_pattern_diffs)
        
        avg_val_loss = np.mean(val_losses)
        avg_val_action = np.mean(val_action_losses)
        avg_val_classification = np.mean(val_classification_losses)
        avg_val_diversity = np.mean(val_diversity_losses)
        avg_val_specialization = np.mean(val_specialization_losses)
        avg_val_entropy = np.mean(val_entropy_losses)
        avg_val_dynamic = np.mean(val_dynamic_losses)
        avg_val_accuracy = np.mean(val_accuracies)
        avg_val_pattern_diff = np.mean(val_pattern_diffs)
        
        # 更新学习率
        scheduler.step(avg_val_loss)
        
        # 打印进度 - 每10个epoch打印一次
        if epoch % 10 == 0:
            print(f"Epoch {epoch+1}/{training_config['epochs']} - "
                  f"Total: {avg_train_loss:.4f}, Val: {avg_val_loss:.4f}, "
                  f"Action: {avg_train_action:.4f}, Class: {avg_train_classification:.4f}, "
                  f"Div: {avg_train_diversity:.4f}, Spec: {avg_train_specialization:.4f}, "
                  f"Ent: {avg_train_entropy:.4f}, Acc: {avg_train_accuracy:.3f}, "
                  f"Pattern: {avg_train_pattern_diff:.3f}, LR: {optimizer.param_groups[0]['lr']:.6f}")
        
        # 保存最佳模型
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'model_config': model_config,
                'training_config': training_config,
                'best_val_loss': best_val_loss,
                'pattern_diff': avg_val_pattern_diff,
                'val_accuracy': avg_val_accuracy
            }
            
            torch.save(checkpoint, os.path.join(save_dir, 'best_model.pth'))
            print(f"  保存最佳模型 - Val Loss: {best_val_loss:.4f}, Acc: {avg_val_accuracy:.3f}")
        else:
            patience_counter += 1
        
        # 早停
        if patience_counter >= patience:
            print(f"早停: {patience} 轮验证损失没有改善")
            break
    
    print("训练完成!")
    print(f"最佳验证损失: {best_val_loss:.4f}")
    print(f"模型参数数量: {total_params:,}")
    print(f"估算模型大小: {estimated_size_mb:.1f}MB")
    
    return model, model_config, training_config

if __name__ == "__main__":
    model, model_config, training_config = train_joint_specialized_model()