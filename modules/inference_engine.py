#!/usr/bin/env python3
"""
Diffusion Policy æ¨ç†é€»è¾‘
åŒ…å«åŠ¨ä½œåºåˆ—ç”Ÿæˆã€æ»‘åŠ¨çª—å£æ¨ç†å’Œå¤šä»»åŠ¡æ¨ç†
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, Any, List, Tuple, Optional, Union
import time
from pathlib import Path
import json
import matplotlib.pyplot as plt
from collections import deque

from modules.diffusion_policy import LargeBehaviorModel, create_large_behavior_model
from modules.data_preprocessing import ActionChunkPreprocessor


class DiffusionInferenceEngine:
    """
    Diffusion æ¨ç†å¼•æ“
    """
    
    def __init__(self, 
                 model: LargeBehaviorModel,
                 device: str = 'cuda',
                 chunk_length: int = 16,
                 sliding_window_overlap: int = 4):
        """
        åˆå§‹åŒ–æ¨ç†å¼•æ“
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            device: è®¾å¤‡
            chunk_length: åŠ¨ä½œå—é•¿åº¦
            sliding_window_overlap: æ»‘åŠ¨çª—å£é‡å é•¿åº¦
        """
        self.model = model.to(device)
        self.device = device
        self.chunk_length = chunk_length
        self.sliding_window_overlap = sliding_window_overlap
        self.model.eval()
        
        # çŠ¶æ€ç¼“å­˜
        self.state_history = deque(maxlen=10)
        self.action_history = deque(maxlen=50)
        
        # æŒ‡ä»¤æ˜ å°„
        self.instruction_map = {'wave': 0, 'welcome': 1}
        self.instruction_to_name = {v: k for k, v in self.instruction_map.items()}
    
    def generate_action_chunk(self, 
                            instruction: str,
                            state: np.ndarray,
                            visual_features: Optional[np.ndarray] = None,
                            num_sampling_steps: int = 100,
                            guidance_scale: float = 1.5,
                            temperature: float = 1.0) -> np.ndarray:
        """
        ç”ŸæˆåŠ¨ä½œå—
        
        Args:
            instruction: æŒ‡ä»¤å­—ç¬¦ä¸²
            state: å½“å‰çŠ¶æ€ [state_dim]
            visual_features: è§†è§‰ç‰¹å¾ [visual_feature_dim]
            num_sampling_steps: é‡‡æ ·æ­¥æ•°
            guidance_scale: å¼•å¯¼å¼ºåº¦
            temperature: æ¸©åº¦å‚æ•°
            
        Returns:
            ç”Ÿæˆçš„åŠ¨ä½œå— [chunk_length, action_dim]
        """
        # è½¬æ¢ä¸ºtensor
        instruction_id = torch.tensor([self.instruction_map[instruction]], dtype=torch.long).to(self.device)
        state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)
        
        # å¤„ç†è§†è§‰ç‰¹å¾
        visual_tensor = None
        if visual_features is not None:
            visual_tensor = torch.tensor(visual_features, dtype=torch.float32).unsqueeze(0).to(self.device)
        
        # ç”ŸæˆåŠ¨ä½œåºåˆ—
        with torch.no_grad():
            action_chunk = self.model.generate_action_sequence(
                instruction_ids=instruction_id,
                state=state_tensor,
                visual_features=visual_tensor,
                num_steps=num_sampling_steps,
                guidance_scale=guidance_scale
            )
        
        # åº”ç”¨æ¸©åº¦
        if temperature != 1.0:
            action_chunk = action_chunk * temperature
        
        # è½¬æ¢ä¸ºnumpy
        return action_chunk.squeeze(0).cpu().numpy()
    
    def sliding_window_inference(self, 
                               instruction: str,
                               initial_state: np.ndarray,
                               total_steps: int,
                               visual_features_sequence: Optional[List[np.ndarray]] = None,
                               num_sampling_steps: int = 100,
                               guidance_scale: float = 1.5,
                               temperature: float = 1.0) -> List[np.ndarray]:
        """
        æ»‘åŠ¨çª—å£æ¨ç†
        
        Args:
            instruction: æŒ‡ä»¤å­—ç¬¦ä¸²
            initial_state: åˆå§‹çŠ¶æ€ [state_dim]
            total_steps: æ€»æ­¥æ•°
            visual_features_sequence: è§†è§‰ç‰¹å¾åºåˆ—
            num_sampling_steps: é‡‡æ ·æ­¥æ•°
            guidance_scale: å¼•å¯¼å¼ºåº¦
            temperature: æ¸©åº¦å‚æ•°
            
        Returns:
            å®Œæ•´åŠ¨ä½œåºåˆ—
        """
        all_actions = []
        current_state = initial_state.copy()
        
        # è®¡ç®—éœ€è¦ç”Ÿæˆçš„å—æ•°
        num_chunks = (total_steps + self.chunk_length - 1) // self.chunk_length
        
        for chunk_idx in range(num_chunks):
            print(f"ç”Ÿæˆç¬¬ {chunk_idx + 1}/{num_chunks} ä¸ªåŠ¨ä½œå—...")
            
            # è·å–å½“å‰è§†è§‰ç‰¹å¾
            current_visual = None
            if visual_features_sequence and chunk_idx < len(visual_features_sequence):
                current_visual = visual_features_sequence[chunk_idx]
            
            # ç”Ÿæˆå½“å‰å—
            action_chunk = self.generate_action_chunk(
                instruction=instruction,
                state=current_state,
                visual_features=current_visual,
                num_sampling_steps=num_sampling_steps,
                guidance_scale=guidance_scale,
                temperature=temperature
            )
            
            # æ·»åŠ åˆ°åŠ¨ä½œåºåˆ—
            all_actions.append(action_chunk)
            
            # æ›´æ–°çŠ¶æ€ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œä½¿ç”¨æœ€åä¸€ä¸ªåŠ¨ä½œä½œä¸ºæ–°çŠ¶æ€ï¼‰
            last_action = action_chunk[-1]
            current_state = self._update_state(current_state, last_action)
            
            # æ›´æ–°å†å²
            self.state_history.append(current_state.copy())
            self.action_history.extend(action_chunk)
        
        # å¤„ç†æœ€åä¸€æ­¥ï¼Œç¡®ä¿æ€»æ­¥æ•°æ­£ç¡®
        if len(all_actions) * self.chunk_length > total_steps:
            # æˆªæ–­å¤šä½™çš„æ­¥éª¤
            final_actions = []
            remaining_steps = total_steps
            
            for chunk in all_actions:
                if remaining_steps <= 0:
                    break
                take_steps = min(len(chunk), remaining_steps)
                final_actions.append(chunk[:take_steps])
                remaining_steps -= take_steps
            
            all_actions = final_actions
        
        return all_actions
    
    def _update_state(self, current_state: np.ndarray, action: np.ndarray) -> np.ndarray:
        """
        æ›´æ–°çŠ¶æ€ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        
        Args:
            current_state: å½“å‰çŠ¶æ€
            action: æ‰§è¡Œçš„åŠ¨ä½œ
            
        Returns:
            æ›´æ–°åçš„çŠ¶æ€
        """
        new_state = current_state.copy()
        
        # ç®€å•çš„çŠ¶æ€æ›´æ–°ï¼šå°†åŠ¨ä½œæ·»åŠ åˆ°ä½ç½®
        if len(action) >= len(new_state):
            new_state = action[:len(new_state)]
        else:
            new_state[:len(action)] = action
        
        # æ·»åŠ ä¸€äº›å™ªå£°ä½¿å…¶æ›´çœŸå®
        noise = np.random.normal(0, 0.01, len(new_state))
        new_state += noise
        
        return new_state
    
    def multi_task_inference(self, 
                           task_sequence: List[Tuple[str, int]],
                           initial_state: np.ndarray,
                           visual_features_dict: Optional[Dict[str, List[np.ndarray]]] = None,
                           num_sampling_steps: int = 50,
                           guidance_scale: float = 1.0) -> Dict[str, List[np.ndarray]]:
        """
        å¤šä»»åŠ¡æ¨ç†
        
        Args:
            task_sequence: ä»»åŠ¡åºåˆ— [(instruction, num_steps), ...]
            initial_state: åˆå§‹çŠ¶æ€
            visual_features_dict: è§†è§‰ç‰¹å¾å­—å…¸
            num_sampling_steps: é‡‡æ ·æ­¥æ•°
            guidance_scale: å¼•å¯¼å¼ºåº¦
            
        Returns:
            æ¯ä¸ªä»»åŠ¡çš„åŠ¨ä½œåºåˆ—
        """
        task_results = {}
        current_state = initial_state.copy()
        
        for instruction, num_steps in task_sequence:
            print(f"\nğŸ¯ æ‰§è¡Œä»»åŠ¡: {instruction} ({num_steps} æ­¥)")
            
            # è·å–è§†è§‰ç‰¹å¾
            visual_sequence = None
            if visual_features_dict and instruction in visual_features_dict:
                visual_sequence = visual_features_dict[instruction]
            
            # ç”ŸæˆåŠ¨ä½œåºåˆ—
            task_actions = self.sliding_window_inference(
                instruction=instruction,
                initial_state=current_state,
                total_steps=num_steps,
                visual_features_sequence=visual_sequence,
                num_sampling_steps=num_sampling_steps,
                guidance_scale=guidance_scale
            )
            
            task_results[instruction] = task_actions
            
            # æ›´æ–°çŠ¶æ€ä¸ºæœ€åä¸€ä¸ªåŠ¨ä½œ
            if task_actions:
                last_action = task_actions[-1][-1]
                current_state = self._update_state(current_state, last_action)
        
        return task_results
    
    def evaluate_action_quality(self, 
                               generated_actions: List[np.ndarray],
                               reference_actions: Optional[List[np.ndarray]] = None) -> Dict[str, float]:
        """
        è¯„ä¼°åŠ¨ä½œè´¨é‡
        
        Args:
            generated_actions: ç”Ÿæˆçš„åŠ¨ä½œåºåˆ—
            reference_actions: å‚è€ƒåŠ¨ä½œåºåˆ—ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            è´¨é‡æŒ‡æ ‡
        """
        # å±•å¹³åŠ¨ä½œåºåˆ—
        flat_actions = np.vstack(generated_actions)
        
        # åŸºæœ¬ç»Ÿè®¡
        metrics = {
            'mean_action': float(np.mean(flat_actions)),
            'std_action': float(np.std(flat_actions)),
            'min_action': float(np.min(flat_actions)),
            'max_action': float(np.max(flat_actions)),
            'total_steps': len(flat_actions)
        }
        
        # åŠ¨ä½œå˜åŒ–åˆ†æ
        if len(flat_actions) > 1:
            action_diffs = np.diff(flat_actions, axis=0)
            metrics['mean_change'] = float(np.mean(np.abs(action_diffs)))
            metrics['max_change'] = float(np.max(np.abs(action_diffs)))
            metrics['action_variance'] = float(np.var(action_diffs))
        
        # æŒ¯è¡åˆ†æ
        if len(flat_actions) > 2:
            velocity = np.diff(flat_actions, axis=0)
            acceleration = np.diff(velocity, axis=0)
            
            # è®¡ç®—ç¬¦å·å˜åŒ–ï¼ˆæŒ¯è¡æŒ‡æ ‡ï¼‰
            sign_changes = 0
            for i in range(len(velocity) - 1):
                sign_changes += np.sum(np.sign(velocity[i]) != np.sign(velocity[i+1]))
            
            total_comparisons = len(velocity) - 1
            metrics['oscillation_rate'] = sign_changes / (total_comparisons * flat_actions.shape[1]) if total_comparisons > 0 else 0
            metrics['mean_acceleration'] = float(np.mean(np.abs(acceleration)))
        
        # å¦‚æœæœ‰å‚è€ƒåŠ¨ä½œï¼Œè®¡ç®—ç›¸ä¼¼åº¦
        if reference_actions is not None:
            flat_reference = np.vstack(reference_actions)
            
            # ç¡®ä¿é•¿åº¦ä¸€è‡´
            min_len = min(len(flat_actions), len(flat_reference))
            flat_actions_aligned = flat_actions[:min_len]
            flat_reference_aligned = flat_reference[:min_len]
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = self._calculate_similarity(flat_actions_aligned, flat_reference_aligned)
            metrics['similarity_to_reference'] = similarity
            
            # è®¡ç®—MSE
            mse = np.mean((flat_actions_aligned - flat_reference_aligned) ** 2)
            metrics['mse_to_reference'] = float(mse)
        
        return metrics
    
    def _calculate_similarity(self, seq1: np.ndarray, seq2: np.ndarray) -> float:
        """
        è®¡ç®—åºåˆ—ç›¸ä¼¼åº¦
        """
        if seq1.shape != seq2.shape:
            return 0.0
        
        seq1_flat = seq1.flatten()
        seq2_flat = seq2.flatten()
        
        dot_product = np.dot(seq1_flat, seq2_flat)
        norm1 = np.linalg.norm(seq1_flat)
        norm2 = np.linalg.norm(seq2_flat)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot_product / (norm1 * norm2)
    
    def visualize_generation(self, 
                           generated_actions: List[np.ndarray],
                           reference_actions: Optional[List[np.ndarray]] = None,
                           save_path: Optional[str] = None):
        """
        å¯è§†åŒ–ç”Ÿæˆçš„åŠ¨ä½œåºåˆ—
        
        Args:
            generated_actions: ç”Ÿæˆçš„åŠ¨ä½œåºåˆ—
            reference_actions: å‚è€ƒåŠ¨ä½œåºåˆ—
            save_path: ä¿å­˜è·¯å¾„
        """
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # å±•å¹³åŠ¨ä½œåºåˆ—
        flat_generated = np.vstack(generated_actions)
        
        # ç»˜åˆ¶ç”Ÿæˆçš„åŠ¨ä½œåºåˆ—
        time_steps = np.arange(len(flat_generated))
        
        # é€‰æ‹©å‰6ä¸ªå…³èŠ‚è¿›è¡Œç»˜åˆ¶
        important_joints = [0, 1, 2, 3, 4, 5]
        
        for i, joint_idx in enumerate(important_joints[:3]):
            axes[0, 0].plot(time_steps, flat_generated[:, joint_idx], 
                           label=f'Joint {joint_idx}', linewidth=2)
        
        axes[0, 0].set_title('Generated Action Sequence')
        axes[0, 0].set_xlabel('Time Step')
        axes[0, 0].set_ylabel('Action Value')
        axes[0, 0].legend()
        axes[0, 0].grid(True)
        
        # ç»˜åˆ¶åŠ¨ä½œå˜åŒ–
        if len(flat_generated) > 1:
            action_diffs = np.diff(flat_generated, axis=0)
            diff_steps = np.arange(len(action_diffs))
            
            for i, joint_idx in enumerate(important_joints[:3]):
                axes[0, 1].plot(diff_steps, action_diffs[:, joint_idx], 
                               label=f'Joint {joint_idx}', linewidth=2)
        
        axes[0, 1].set_title('Action Changes')
        axes[0, 1].set_xlabel('Time Step')
        axes[0, 1].set_ylabel('Action Change')
        axes[0, 1].legend()
        axes[0, 1].grid(True)
        
        # ç»˜åˆ¶å…³èŠ‚è½¨è¿¹
        for i, joint_idx in enumerate(important_joints[:3]):
            axes[1, 0].plot(flat_generated[:, joint_idx], flat_generated[:, joint_idx+1], 
                           'o-', markersize=3, label=f'Joint {joint_idx} vs {joint_idx+1}')
        
        axes[1, 0].set_title('Joint Trajectories')
        axes[1, 0].set_xlabel(f'Joint {important_joints[0]}')
        axes[1, 0].set_ylabel(f'Joint {important_joints[1]}')
        axes[1, 0].legend()
        axes[1, 0].grid(True)
        
        # ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯
        metrics = self.evaluate_action_quality(generated_actions, reference_actions)
        
        stats_text = f"""
        Generation Statistics:
        Total Steps: {metrics['total_steps']}
        Mean Action: {metrics['mean_action']:.4f}
        Std Action: {metrics['std_action']:.4f}
        Mean Change: {metrics['mean_change']:.4f}
        Oscillation Rate: {metrics['oscillation_rate']:.3f}
        
        {'Similarity: {:.4f}'.format(metrics.get('similarity_to_reference', 0)) if 'similarity_to_reference' in metrics else ''}
        {'MSE: {:.6f}'.format(metrics.get('mse_to_reference', 0)) if 'mse_to_reference' in metrics else ''}
        """
        
        axes[1, 1].text(0.1, 0.5, stats_text, transform=axes[1, 1].transAxes, 
                       fontsize=12, verticalalignment='center', fontfamily='monospace')
        axes[1, 1].set_title('Generation Statistics')
        axes[1, 1].axis('off')
        
        # å¦‚æœæœ‰å‚è€ƒåŠ¨ä½œï¼Œç»˜åˆ¶å¯¹æ¯”
        if reference_actions is not None:
            flat_reference = np.vstack(reference_actions)
            min_len = min(len(flat_generated), len(flat_reference))
            
            # åˆ›å»ºæ–°çš„å¯¹æ¯”å›¾
            fig2, axes2 = plt.subplots(1, 1, figsize=(12, 6))
            
            time_steps_aligned = np.arange(min_len)
            
            for i, joint_idx in enumerate(important_joints[:3]):
                axes2.plot(time_steps_aligned, flat_generated[:min_len, joint_idx], 
                          label=f'Generated Joint {joint_idx}', linewidth=2)
                axes2.plot(time_steps_aligned, flat_reference[:min_len, joint_idx], 
                          label=f'Reference Joint {joint_idx}', linewidth=2, linestyle='--')
            
            axes2.set_title('Generated vs Reference Actions')
            axes2.set_xlabel('Time Step')
            axes2.set_ylabel('Action Value')
            axes2.legend()
            axes2.grid(True)
            
            if save_path:
                comparison_path = save_path.replace('.png', '_comparison.png')
                plt.savefig(comparison_path, dpi=300, bbox_inches='tight')
                print(f"å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {comparison_path}")
            
            # è®­ç»ƒæœŸé—´ä¸æ˜¾ç¤ºå›¾è¡¨
            if not save_path:
                plt.show()
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ç”Ÿæˆå›¾å·²ä¿å­˜åˆ°: {save_path}")
        
        # è®­ç»ƒæœŸé—´ä¸æ˜¾ç¤ºå›¾è¡¨
        if not save_path:
            plt.show()
    
    def benchmark_inference(self, 
                          instruction: str,
                          state: np.ndarray,
                          num_runs: int = 10) -> Dict[str, float]:
        """
        åŸºå‡†æµ‹è¯•æ¨ç†æ€§èƒ½
        
        Args:
            instruction: æŒ‡ä»¤å­—ç¬¦ä¸²
            state: çŠ¶æ€
            num_runs: è¿è¡Œæ¬¡æ•°
            
        Returns:
            æ€§èƒ½æŒ‡æ ‡
        """
        print(f"ğŸš€ å¼€å§‹åŸºå‡†æµ‹è¯• ({num_runs} æ¬¡)...")
        
        times = []
        
        for i in range(num_runs):
            start_time = time.time()
            
            # ç”ŸæˆåŠ¨ä½œå—
            action_chunk = self.generate_action_chunk(
                instruction=instruction,
                state=state,
                num_sampling_steps=100,
                guidance_scale=1.5
            )
            
            end_time = time.time()
            times.append(end_time - start_time)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        mean_time = np.mean(times)
        std_time = np.std(times)
        min_time = np.min(times)
        max_time = np.max(times)
        
        # è®¡ç®—FPS
        fps = self.chunk_length / mean_time
        
        return {
            'mean_time': mean_time,
            'std_time': std_time,
            'min_time': min_time,
            'max_time': max_time,
            'fps': fps,
            'total_params': sum(p.numel() for p in self.model.parameters())
        }


def create_inference_engine(model_path: str, device: str = 'cuda') -> DiffusionInferenceEngine:
    """
    åˆ›å»ºæ¨ç†å¼•æ“
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„
        device: è®¾å¤‡
        
    Returns:
        æ¨ç†å¼•æ“å®ä¾‹
    """
    # åŠ è½½æ¨¡å‹
    checkpoint = torch.load(model_path, map_location='cpu')
    
    # åˆ›å»ºæ¨¡å‹
    model = create_large_behavior_model()
    
    # åŠ è½½æƒé‡
    model.load_state_dict(checkpoint['model_state_dict'])
    
    # åˆ›å»ºæ¨ç†å¼•æ“
    engine = DiffusionInferenceEngine(
        model=model,
        device=device,
        chunk_length=16,
        sliding_window_overlap=4
    )
    
    return engine


def test_inference_engine():
    """æµ‹è¯•æ¨ç†å¼•æ“"""
    print("æµ‹è¯•æ¨ç†å¼•æ“...")
    
    # åˆ›å»ºè™šæ‹Ÿæ¨¡å‹
    model = create_large_behavior_model({
        'action_dim': 26,
        'chunk_length': 16,
        'state_dim': 60,
        'diffusion_dim': 256,
        'num_diffusion_steps': 100
    })
    
    # åˆ›å»ºæ¨ç†å¼•æ“
    engine = DiffusionInferenceEngine(model, device='cpu')
    
    # æµ‹è¯•æ•°æ®
    instruction = 'wave'
    state = np.random.randn(60)
    
    # æµ‹è¯•åŠ¨ä½œç”Ÿæˆ
    action_chunk = engine.generate_action_chunk(instruction, state, num_sampling_steps=100)
    print(f"ç”Ÿæˆçš„åŠ¨ä½œå—å½¢çŠ¶: {action_chunk.shape}")
    
    # æµ‹è¯•æ»‘åŠ¨çª—å£æ¨ç†
    actions = engine.sliding_window_inference(instruction, state, total_steps=32)
    print(f"ç”Ÿæˆçš„åŠ¨ä½œåºåˆ—å—æ•°: {len(actions)}")
    
    # æµ‹è¯•è´¨é‡è¯„ä¼°
    metrics = engine.evaluate_action_quality(actions)
    print(f"åŠ¨ä½œè´¨é‡æŒ‡æ ‡: {metrics}")
    
    print("æ¨ç†å¼•æ“æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    test_inference_engine()