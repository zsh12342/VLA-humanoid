#!/usr/bin/env python3
"""
Diffusion Policy è®­ç»ƒé€»è¾‘
åŒ…å«è®­ç»ƒå¾ªç¯ã€æŸå¤±å‡½æ•°å’Œå¤šä»»åŠ¡æ··åˆè®­ç»ƒç­–ç•¥
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, Any, List, Tuple, Optional, Iterator
from torch.utils.data import Dataset, DataLoader
import json
from pathlib import Path
import time
from tqdm import tqdm
import random
from scipy import ndimage
try:
    import wandb
    HAS_WANDB = True
except ImportError:
    HAS_WANDB = False
from collections import defaultdict

from modules.diffusion_policy import LargeBehaviorModel, create_large_behavior_model
from modules.data_preprocessing import ActionChunkPreprocessor


class EnhancedDiffusionLoss(nn.Module):
    """
    å¢å¼ºç‰ˆDiffusionæŸå¤±å‡½æ•°
    åŒ…å«å¹³æ»‘æ€§çº¦æŸå’Œç‰©ç†ä¸€è‡´æ€§
    """
    
    def __init__(self, 
                 num_diffusion_steps: int = 1000,
                 beta_schedule: str = 'cosine',
                 beta_start: float = 0.0001,
                 beta_end: float = 0.02,
                 smoothness_weight: float = 0.02,
                 consistency_weight: float = 0.01,
                 velocity_weight: float = 0.15):
        super().__init__()
        
        self.num_diffusion_steps = num_diffusion_steps
        self.beta_schedule = beta_schedule
        self.smoothness_weight = smoothness_weight
        self.consistency_weight = consistency_weight
        self.velocity_weight = velocity_weight
        
        # è®¡ç®—å™ªå£°è°ƒåº¦
        if beta_schedule == 'linear':
            betas = torch.linspace(beta_start, beta_end, num_diffusion_steps)
        elif beta_schedule == 'cosine':
            betas = self._cosine_beta_schedule(num_diffusion_steps)
        else:
            raise ValueError(f"Unknown beta schedule: {beta_schedule}")
        
        # æ³¨å†Œä¸ºbuffer
        self.register_buffer('betas', betas)
        
        # è®¡ç®—alphaç›¸å…³å‚æ•°
        alphas = 1.0 - self.betas
        alphas_cumprod = torch.cumprod(alphas, dim=0)
        alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)
        
        # è®¡ç®—æ‰©æ•£è¿‡ç¨‹çš„å‚æ•°
        sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)
        sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)
        
        # è®¡ç®—åéªŒå‚æ•°
        posterior_variance = self.betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)
        posterior_log_variance_clipped = torch.log(
            torch.clamp(posterior_variance, min=1e-20)
        )
        posterior_mean_coef1 = self.betas * torch.sqrt(alphas_cumprod_prev) / (1.0 - alphas_cumprod)
        posterior_mean_coef2 = (1.0 - alphas_cumprod_prev) * torch.sqrt(alphas) / (1.0 - alphas_cumprod)
        
        # æ³¨å†Œæ‰€æœ‰å¼ é‡ä¸ºbuffer
        self.register_buffer('alphas', alphas)
        self.register_buffer('alphas_cumprod', alphas_cumprod)
        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)
        self.register_buffer('sqrt_alphas_cumprod', sqrt_alphas_cumprod)
        self.register_buffer('sqrt_one_minus_alphas_cumprod', sqrt_one_minus_alphas_cumprod)
        self.register_buffer('posterior_variance', posterior_variance)
        self.register_buffer('posterior_log_variance_clipped', posterior_log_variance_clipped)
        self.register_buffer('posterior_mean_coef1', posterior_mean_coef1)
        self.register_buffer('posterior_mean_coef2', posterior_mean_coef2)
        
        # å…³èŠ‚é™åˆ¶ï¼ˆå¼—å…°å¡æœºæ¢°è‡‚ï¼‰
        self.joint_limits = torch.tensor([
            2.8973, 1.7628, 2.8973, -0.0698, 2.8973, 3.7525, 2.8973,  # å…³èŠ‚1-7
            2.8973, 1.7628, 2.8973, -0.0698, 2.8973, 3.7525, 2.8973,  # å…³èŠ‚8-14
            2.8973, 1.7628, 2.8973, -0.0698, 2.8973, 3.7525, 2.8973,  # å…³èŠ‚15-21
            2.8973, 1.7628, 2.8973, -0.0698, 2.8973                   # å…³èŠ‚22-26
        ])
    
    def _cosine_beta_schedule(self, timesteps: int, s: float = 0.008) -> torch.Tensor:
        """
        æ”¹è¿›çš„ä½™å¼¦è°ƒåº¦ - æ›´å¥½çš„æ”¶æ•›æ€§
        """
        steps = torch.arange(timesteps + 1, dtype=torch.float32) / timesteps
        
        # ä½¿ç”¨æ”¹è¿›çš„ä½™å¼¦è°ƒåº¦ï¼Œåœ¨å‰å‡ æ­¥å’Œåå‡ æ­¥æœ‰æ›´å¹³ç¨³çš„è¿‡æ¸¡
        alpha_bar = torch.cos((steps + s) / (1 + s) * torch.pi * 0.5) ** 2
        
        # æ·»åŠ çº¿æ€§æ’å€¼ä»¥æ”¹å–„æ—©æœŸå’Œæ™šæœŸçš„ç¨³å®šæ€§
        if timesteps > 10:
            # å‰10%ä½¿ç”¨æ›´æ¸©å’Œçš„è°ƒåº¦
            early_phase = int(timesteps * 0.1)
            early_alpha = torch.linspace(1.0, alpha_bar[early_phase], early_phase + 1)
            alpha_bar[:early_phase + 1] = early_alpha
            
            # å10%ä¹Ÿä½¿ç”¨æ¸©å’Œè°ƒåº¦
            late_phase = int(timesteps * 0.9)
            late_alpha = torch.linspace(alpha_bar[late_phase], alpha_bar[-1], timesteps - late_phase + 1)
            alpha_bar[late_phase:] = late_alpha
        
        betas = 1 - alpha_bar[1:] / alpha_bar[:-1]
        
        # ç¡®ä¿betaå€¼åœ¨åˆç†èŒƒå›´å†…
        betas = torch.clamp(betas, 1e-4, 0.999)
        
        return betas
    
    def q_sample(self, 
                 x_start: torch.Tensor, 
                 t: torch.Tensor, 
                 noise: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        å‰å‘æ‰©æ•£è¿‡ç¨‹
        
        Args:
            x_start: åŸå§‹æ•°æ® [batch_size, ...]
            t: æ—¶é—´æ­¥ [batch_size]
            noise: å™ªå£° [batch_size, ...]
            
        Returns:
            å¸¦å™ªå£°çš„æ•°æ®
        """
        if noise is None:
            noise = torch.randn_like(x_start)
        
        # ç¡®ä¿ç´¢å¼•å’Œç¼“å†²åŒºåœ¨åŒä¸€è®¾å¤‡ä¸Š
        device = x_start.device
        t = t.to(device)
        
        sqrt_alpha_cumprod = self.sqrt_alphas_cumprod.to(device)[t].view(-1, 1, 1)
        sqrt_one_minus_alpha_cumprod = self.sqrt_one_minus_alphas_cumprod.to(device)[t].view(-1, 1, 1)
        
        return sqrt_alpha_cumprod * x_start + sqrt_one_minus_alpha_cumprod * noise
    
    def compute_loss(self, 
                     model: LargeBehaviorModel,
                     x_start: torch.Tensor,
                     instruction_ids: torch.Tensor,
                     state: torch.Tensor,
                     visual_features: Optional[torch.Tensor] = None,
                     noise: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """
        è®¡ç®—å¢å¼ºçš„æ‰©æ•£æŸå¤±
        
        Args:
            model: æ¨¡å‹
            x_start: åŸå§‹åŠ¨ä½œåºåˆ— [batch_size, chunk_length, action_dim]
            instruction_ids: æŒ‡ä»¤ID [batch_size]
            state: çŠ¶æ€ä¿¡æ¯ [batch_size, state_dim]
            visual_features: è§†è§‰ç‰¹å¾ [batch_size, visual_feature_dim]
            noise: å™ªå£° [batch_size, chunk_length, action_dim]
            
        Returns:
            æŸå¤±å­—å…¸
        """
        batch_size = x_start.shape[0]
        device = x_start.device
        
        # éšæœºæ—¶é—´æ­¥
        t = torch.randint(0, self.num_diffusion_steps, (batch_size,), device=device)
        
        # ç”Ÿæˆå™ªå£°
        if noise is None:
            noise = torch.randn_like(x_start)
        
        # å‰å‘æ‰©æ•£
        x_t = self.q_sample(x_start, t, noise)
        
        # é¢„æµ‹å™ªå£°
        predicted_noise = model(
            instruction_ids=instruction_ids,
            state=state,
            noisy_actions=x_t,
            timesteps=t,
            visual_features=visual_features
        )
        
        # è®¡ç®—MSEæŸå¤± - ä¸ä½¿ç”¨æ ‡ç­¾å¹³æ»‘
        mse_loss = F.mse_loss(predicted_noise, noise, reduction='mean')
        
        # è®¡ç®—å¹³æ»‘æ€§æŸå¤±
        smoothness_loss = self._compute_smoothness_loss(predicted_noise)
        
        # è®¡ç®—ç‰©ç†ä¸€è‡´æ€§æŸå¤±
        consistency_loss = self._compute_consistency_loss(x_start)
        
        # è®¡ç®—é€Ÿåº¦è¿ç»­æ€§æŸå¤±
        velocity_loss = self._compute_velocity_loss(x_start)
        
        # è®¡ç®—æ—¶é—´ä¸€è‡´æ€§æŸå¤±ï¼ˆæ”¹è¿›å±€éƒ¨ç‰¹å¾å¤ç°ï¼‰
        temporal_loss = self._compute_temporal_consistency_loss(x_start, predicted_noise)
        
        # è®¡ç®—èŒƒå›´æŸå¤± - å¼ºåˆ¶è¾“å‡ºåœ¨æ•°æ®é›†èŒƒå›´å†…
        range_loss = self._compute_range_loss(x_start)
        
        # æ·»åŠ æ›²çº¿ä¿çœŸåº¦æŸå¤±
        curvature_loss = torch.tensor(0.0, device=x_start.device)
        if x_start.shape[1] > 2:
            # è®¡ç®—åŸå§‹æ•°æ®çš„äºŒé˜¶å·®åˆ†ï¼ˆæ›²ç‡ç‰¹å¾ï¼‰
            original_curvature = torch.diff(x_start, dim=1, n=2)
            
            # ä½¿ç”¨é¢„æµ‹å™ªå£°è¿‘ä¼¼é‡æ„åŠ¨ä½œ
            alpha_t = 1.0 - (t.float() / self.num_diffusion_steps).view(-1, 1, 1)
            predicted_x = x_start - predicted_noise * (1 - alpha_t).sqrt()
            predicted_curvature = torch.diff(predicted_x, dim=1, n=2)
            
            # æ›²çº¿å½¢çŠ¶ä¿æŒæŸå¤±
            curvature_loss = F.mse_loss(predicted_curvature, original_curvature)
        
        # æ·»åŠ åŠ¨æ€æ€§æ¿€åŠ± - é¼“åŠ±ç”Ÿæˆæœ‰å˜åŒ–çš„åŠ¨ä½œ
        dynamic_loss = self._compute_dynamic_loss(x_start)
        
        # æ€»æŸå¤± - æåº¦ç®€åŒ–ï¼Œå‡ ä¹åªä½¿ç”¨MSEæŸå¤±
        total_loss = (mse_loss + 
                     0.001 * smoothness_loss +    # æåº¦å‡å°‘å¹³æ»‘æ€§çº¦æŸ
                     0.0005 * consistency_loss + # æåº¦å‡å°‘ä¸€è‡´æ€§çº¦æŸ
                     0.001 * velocity_loss +      # æåº¦å‡å°‘é€Ÿåº¦çº¦æŸ
                     0.001 * temporal_loss +      # æåº¦å‡å°‘æ—¶é—´ä¸€è‡´æ€§
                     0.001 * curvature_loss +     # æåº¦å‡å°‘æ›²çº¿ä¿çœŸåº¦
                     0.001 * range_loss +        # æåº¦å‡å°‘èŒƒå›´é™åˆ¶
                     0.01 * dynamic_loss)        # è½»å¾®é¼“åŠ±åŠ¨æ€æ€§
        
        return {
            'loss': total_loss,
            'mse_loss': mse_loss,
            'smoothness_loss': smoothness_loss,
            'consistency_loss': consistency_loss,
            'velocity_loss': velocity_loss,
            'temporal_loss': temporal_loss,
            'curvature_loss': curvature_loss,  # æ–°å¢
            'range_loss': range_loss,  # æ–°å¢èŒƒå›´æŸå¤±
            'dynamic_loss': dynamic_loss,  # æ–°å¢åŠ¨æ€æ€§æŸå¤±
            'predicted_noise': predicted_noise,
            'target_noise': noise,
            'timesteps': t
        }
    
    def _compute_smoothness_loss(self, predicted_noise: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—å¹³æ»‘æ€§æŸå¤± - æåº¦å®½æ¾ç‰ˆæœ¬ï¼Œå‡ ä¹ä¸é™åˆ¶"""
        # åªæƒ©ç½šæç«¯çš„é«˜é¢‘å˜åŒ–
        noise_diff = torch.diff(predicted_noise, dim=1)
        
        # æåº¦å®½æ¾çš„é™åˆ¶
        max_reasonable_change = 10.0  # å…è®¸éå¸¸å¤§çš„å˜åŒ–
        extreme_changes = torch.relu(torch.abs(noise_diff) - max_reasonable_change)
        smoothness_loss = torch.mean(extreme_changes ** 2)
        
        return smoothness_loss
    
    def _compute_consistency_loss(self, x_start: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—ç‰©ç†ä¸€è‡´æ€§æŸå¤± - æåº¦å®½æ¾ç‰ˆæœ¬"""
        device = x_start.device
        joint_limits = self.joint_limits.to(device)
        
        # åªæƒ©ç½šæç«¯çš„å…³èŠ‚é™åˆ¶è¿å
        violations = torch.relu(torch.abs(x_start) - joint_limits.unsqueeze(0).unsqueeze(0) * 2.0)  # å…è®¸è¶…å‡º2å€
        consistency_loss = torch.mean(violations ** 2) * 0.1  # æåº¦å‡å°‘æƒé‡
        
        return consistency_loss
    
    def _compute_range_loss(self, x_start: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—èŒƒå›´æŸå¤± - æåº¦å®½æ¾ç‰ˆæœ¬ï¼ŒåŸºæœ¬ä¸é™åˆ¶èŒƒå›´"""
        # ä½¿ç”¨æ•°æ®é›†çš„å®é™…èŒƒå›´ï¼Œä½†å…è®¸å¾ˆå¤§ç¨‹åº¦çš„è¶…å‡º
        data_min = -2.9459
        data_max = 1.4640
        
        # å…è®¸è¶…å‡ºæ•°æ®é›†èŒƒå›´3å€ï¼Œåªé˜²æ­¢æç«¯å€¼
        soft_min = data_min - 3.0 * (data_max - data_min)
        soft_max = data_max + 3.0 * (data_max - data_min)
        
        # è®¡ç®—è¶…å‡ºèŒƒå›´çš„æƒ©ç½š - æåº¦æ¸©å’Œ
        below_min = torch.relu(soft_min - x_start)
        above_max = torch.relu(x_start - soft_max)
        
        # ä½¿ç”¨æå°çš„æƒ©ç½šæƒé‡
        range_loss = 0.01 * (torch.mean(below_min ** 2) + torch.mean(above_max ** 2))
        
        return range_loss
    
    def _compute_velocity_loss(self, x_start: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—é€Ÿåº¦è¿ç»­æ€§æŸå¤± - æ”¹è¿›ç‰ˆæœ¬ï¼Œå…è®¸åˆç†è¿åŠ¨"""
        if x_start.shape[1] <= 2:
            return torch.tensor(0.0, device=x_start.device)
        
        # è®¡ç®—é€Ÿåº¦ï¼ˆä¸€é˜¶å·®åˆ†ï¼‰
        velocities = torch.diff(x_start, dim=1)  # [batch_size, chunk_length-1, action_dim]
        
        # è®¡ç®—åŠ é€Ÿåº¦ï¼ˆäºŒé˜¶å·®åˆ†ï¼‰
        if x_start.shape[1] > 2:
            accelerations = torch.diff(velocities, dim=1)  # [batch_size, chunk_length-2, action_dim]
            
            # åªæƒ©ç½šæç«¯çš„åŠ é€Ÿåº¦ï¼Œå…è®¸åˆç†çš„è¿åŠ¨
            max_reasonable_accel = 2.0
            extreme_accelerations = torch.relu(torch.abs(accelerations) - max_reasonable_accel)
            acceleration_loss = torch.mean(extreme_accelerations ** 2)
            
            # è½»å¾®æƒ©ç½šé€Ÿåº¦çªå˜ï¼Œä½†ä¿ç•™åŠ¨æ€ç‰¹å¾
            velocity_changes = torch.diff(velocities, dim=1)
            max_reasonable_jerk = 3.0
            extreme_jerks = torch.relu(torch.abs(velocity_changes) - max_reasonable_jerk)
            velocity_jerk_loss = torch.mean(extreme_jerks ** 2)
            
            return 0.1 * acceleration_loss + 0.05 * velocity_jerk_loss
        
        return torch.tensor(0.0, device=x_start.device)
    
    def _compute_temporal_consistency_loss(self, x_start: torch.Tensor, predicted_noise: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—æ—¶é—´ä¸€è‡´æ€§æŸå¤± - æ”¹è¿›å±€éƒ¨ç‰¹å¾å¤ç°"""
        if x_start.shape[1] <= 2:
            return torch.tensor(0.0, device=x_start.device)
        
        # è®¡ç®—åŸå§‹åŠ¨ä½œåºåˆ—çš„å±€éƒ¨æ¨¡å¼
        local_patterns = []
        for i in range(x_start.shape[1] - 1):
            # ç›¸é‚»å¸§çš„å·®å¼‚
            diff = x_start[:, i+1] - x_start[:, i]
            local_patterns.append(diff)
        
        if len(local_patterns) == 0:
            return torch.tensor(0.0, device=x_start.device)
        
        local_patterns = torch.stack(local_patterns, dim=1)  # [batch_size, seq_len-1, action_dim]
        
        # é¼“åŠ±é¢„æµ‹å™ªå£°ä¿æŒç±»ä¼¼çš„æ—¶é—´ç»“æ„
        noise_patterns = []
        for i in range(predicted_noise.shape[1] - 1):
            diff = predicted_noise[:, i+1] - predicted_noise[:, i]
            noise_patterns.append(diff)
        
        if len(noise_patterns) == 0:
            return torch.tensor(0.0, device=x_start.device)
        
        noise_patterns = torch.stack(noise_patterns, dim=1)
        
        # è®¡ç®—æ¨¡å¼ç›¸ä¼¼æ€§æŸå¤±
        pattern_loss = F.mse_loss(noise_patterns, local_patterns, reduction='mean')
        
        # æ·»åŠ å³°å€¼ä¿æŒæŸå¤± - ç‰¹åˆ«å…³æ³¨é‡è¦ç‰¹å¾çš„å¤ç°
        if x_start.shape[1] > 3:
            # æ‰¾åˆ°åŸå§‹åºåˆ—ä¸­çš„å³°å€¼
            x_std = torch.std(x_start, dim=1, keepdim=True)  # [batch_size, 1, action_dim]
            x_mean = torch.mean(x_start, dim=1, keepdim=True)  # [batch_size, 1, action_dim]
            
            # è¯†åˆ«å³°å€¼ç‚¹ï¼ˆåç¦»å‡å€¼è¶…è¿‡æ ‡å‡†å·®çš„ç‚¹ï¼‰
            peak_mask = torch.abs(x_start - x_mean) > 1.5 * x_std  # [batch_size, seq_len, action_dim]
            
            if peak_mask.any():
                # å¯¹å³°å€¼ç‚¹æ–½åŠ æ›´å¼ºçš„çº¦æŸ - ä½¿ç”¨é¢„æµ‹å™ªå£°çš„è‡ªç›¸ä¼¼æ€§
                peak_predicted_noise = predicted_noise[peak_mask]
                if peak_predicted_noise.numel() > 0:
                    # è®¡ç®—å³°å€¼ç‚¹çš„é¢„æµ‹å™ªå£°åº”è¯¥æ›´æ¥è¿‘é›¶ï¼ˆæ›´å‡†ç¡®çš„é¢„æµ‹ï¼‰
                    peak_loss = F.mse_loss(
                        peak_predicted_noise, 
                        torch.zeros_like(peak_predicted_noise), 
                        reduction='mean'
                    )
                    pattern_loss += 0.5 * peak_loss
        
        return pattern_loss
    
    def _compute_dynamic_loss(self, x_start: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—åŠ¨æ€æ€§æŸå¤± - é¼“åŠ±åˆç†çš„åŠ¨æ€å˜åŒ–"""
        if x_start.shape[1] <= 1:
            return torch.tensor(0.0, device=x_start.device)
        
        # è®¡ç®—åŠ¨ä½œçš„å˜åŒ–é‡
        action_changes = torch.diff(x_start, dim=1)
        
        # é¼“åŠ±é€‚åº¦çš„å˜åŒ–ï¼Œè€Œä¸æ˜¯æƒ©ç½šé™æ­¢
        change_magnitude = torch.abs(action_changes)
        target_change = 0.01  # é¼“åŠ±å°å¹…åº¦å˜åŒ–
        
        # å¥–åŠ±æ¥è¿‘ç›®æ ‡å˜åŒ–çš„åŠ¨ä½œ
        dynamic_reward = torch.exp(-torch.abs(change_magnitude - target_change))
        dynamic_loss = -torch.mean(dynamic_reward)  # è´ŸæŸå¤± = æ­£å¥–åŠ±
        
        return dynamic_loss


class DataAugmentation:
    """
    æ•°æ®å¢å¼ºç±» - æé«˜æ•°æ®å¤šæ ·æ€§
    """
    
    def __init__(self, noise_std=0.01, time_warp_prob=0.3, scale_range=(0.9, 1.1)):
        self.noise_std = noise_std
        self.time_warp_prob = time_warp_prob
        self.scale_range = scale_range
    
    def add_noise(self, actions: torch.Tensor) -> torch.Tensor:
        """æ·»åŠ é«˜æ–¯å™ªå£°"""
        noise = torch.randn_like(actions) * self.noise_std
        return actions + noise
    
    def time_warp(self, actions: torch.Tensor) -> torch.Tensor:
        """æ—¶é—´æ‰­æ›²å¢å¼º"""
        if random.random() > self.time_warp_prob:
            return actions
            
        batch_size, seq_len, action_dim = actions.shape
        warped_actions = actions.clone()
        
        for i in range(batch_size):
            # éšæœºé€‰æ‹©æ‰­æ›²ç¨‹åº¦
            warp_factor = random.uniform(0.8, 1.2)
            
            # åº”ç”¨æ—¶é—´æ‰­æ›²
            if warp_factor != 1.0:
                # ä½¿ç”¨çº¿æ€§æ’å€¼è¿›è¡Œæ—¶é—´æ‰­æ›²
                original_indices = torch.arange(seq_len, dtype=torch.float32)
                warped_indices = original_indices * warp_factor
                warped_indices = torch.clamp(warped_indices, 0, seq_len - 1)
                
                for j in range(action_dim):
                    warped_actions[i, :, j] = torch.interp(
                        original_indices, 
                        warped_indices, 
                        actions[i, :, j]
                    )
        
        return warped_actions
    
    def scale_actions(self, actions: torch.Tensor) -> torch.Tensor:
        """åŠ¨ä½œç¼©æ”¾å¢å¼º"""
        scale_factor = random.uniform(*self.scale_range)
        return actions * scale_factor
    
    def random_dropout(self, actions: torch.Tensor, dropout_prob=0.1) -> torch.Tensor:
        """éšæœºä¸¢å¼ƒä¸€äº›åŠ¨ä½œç»´åº¦"""
        mask = torch.rand_like(actions) > dropout_prob
        return actions * mask.float()
    
    def augment(self, actions: torch.Tensor) -> torch.Tensor:
        """ç»¼åˆæ•°æ®å¢å¼º"""
        augmented = actions.clone()
        
        # éšæœºåº”ç”¨å„ç§å¢å¼ºæŠ€æœ¯
        if random.random() < 0.8:  # 80%æ¦‚ç‡æ·»åŠ å™ªå£°
            augmented = self.add_noise(augmented)
        
        if random.random() < 0.3:  # 30%æ¦‚ç‡æ—¶é—´æ‰­æ›²
            augmented = self.time_warp(augmented)
        
        if random.random() < 0.4:  # 40%æ¦‚ç‡ç¼©æ”¾
            augmented = self.scale_actions(augmented)
        
        if random.random() < 0.2:  # 20%æ¦‚ç‡éšæœºä¸¢å¼ƒ
            augmented = self.random_dropout(augmented)
        
        return augmented


class MultiTaskDataset(Dataset):
    """
    å¤šä»»åŠ¡æ•°æ®é›† - æ”¯æŒæ•°æ®å¢å¼º
    """
    
    def __init__(self, 
                 processed_data_list: List[Dict[str, Any]],
                 state_dim: int = 60,
                 action_dim: int = 26,
                 instruction_map: Dict[str, int] = None,
                 use_augmentation: bool = True):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        
        Args:
            processed_data_list: å¤„ç†åçš„æ•°æ®åˆ—è¡¨
            state_dim: çŠ¶æ€ç»´åº¦
            action_dim: åŠ¨ä½œç»´åº¦
            instruction_map: æŒ‡ä»¤æ˜ å°„
        """
        self.processed_data_list = processed_data_list
        self.state_dim = state_dim
        self.action_dim = action_dim
        
        if instruction_map is None:
            instruction_map = {'wave': 0, 'welcome': 1}
        self.instruction_map = instruction_map
        self.instruction_to_name = {v: k for k, v in instruction_map.items()}
        
        # æ•°æ®å¢å¼º
        self.use_augmentation = use_augmentation
        self.augmentation = DataAugmentation() if use_augmentation else None
        
        # æ„å»ºæ•°æ®æ ·æœ¬
        self.samples = self._build_samples()
    
    def _build_samples(self) -> List[Dict[str, Any]]:
        """æ„å»ºæ•°æ®æ ·æœ¬"""
        samples = []
        
        for data in self.processed_data_list:
            task_name = data.get('task_name', 'unknown')
            instruction_id = self.instruction_map.get(task_name, 0)
            
            # è·å–åŠ¨ä½œå—
            action_chunks = data['action_chunks']
            
            # æ„å»ºçŠ¶æ€ä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            if 'processed_observations' in data:
                observations = data['processed_observations']
            else:
                # ä½¿ç”¨åŠ¨ä½œå—çš„ç»Ÿè®¡ä¿¡æ¯æ„å»ºè™šæ‹ŸçŠ¶æ€
                observations = self._build_virtual_states(action_chunks)
            
            # ä¸ºæ¯ä¸ªåŠ¨ä½œå—åˆ›å»ºæ ·æœ¬
            for i, chunk in enumerate(action_chunks):
                # æ„å»ºçŠ¶æ€ï¼ˆä½¿ç”¨è§‚æµ‹æˆ–è™šæ‹ŸçŠ¶æ€ï¼‰
                if i < len(observations):
                    obs = observations[i]
                    state = self._build_state_from_obs(obs)
                else:
                    state = self._build_virtual_state(chunk)
                
                sample = {
                    'task_name': task_name,
                    'instruction_id': instruction_id,
                    'action_chunk': chunk,
                    'state': state,
                    'chunk_index': i,
                    'total_chunks': len(action_chunks)
                }
                samples.append(sample)
        
        return samples
    
    def _build_virtual_states(self, action_chunks: List[List[float]]) -> List[Dict[str, Any]]:
        """æ„å»ºè™šæ‹ŸçŠ¶æ€"""
        virtual_states = []
        
        for chunk in action_chunks:
            # ä½¿ç”¨åŠ¨ä½œå—çš„ç»Ÿè®¡ä¿¡æ¯æ„å»ºè™šæ‹ŸçŠ¶æ€
            chunk_array = np.array(chunk)
            state = {
                'joint_pos': chunk_array[0].tolist(),  # ä½¿ç”¨ç¬¬ä¸€å¸§ä½œä¸ºä½ç½®
                'joint_vel': np.zeros(self.action_dim).tolist(),  # é€Ÿåº¦è®¾ä¸º0
                'joint_torque': np.zeros(self.action_dim).tolist(),  # åŠ›çŸ©è®¾ä¸º0
            }
            virtual_states.append(state)
        
        return virtual_states
    
    def _build_state_from_obs(self, obs: Dict[str, Any]) -> List[float]:
        """ä»è§‚æµ‹æ„å»ºçŠ¶æ€"""
        state = np.zeros(self.state_dim)
        
        # å¡«å……å…³èŠ‚ä¿¡æ¯
        if 'joint_pos' in obs:
            pos = np.array(obs['joint_pos'])
            state[:min(len(pos), self.action_dim)] = pos[:min(len(pos), self.action_dim)]
        
        if 'joint_vel' in obs:
            vel = np.array(obs['joint_vel'])
            start_idx = self.action_dim
            end_idx = min(start_idx + len(vel), self.state_dim)
            state[start_idx:end_idx] = vel[:end_idx - start_idx]
        
        if 'joint_torque' in obs:
            torque = np.array(obs['joint_torque'])
            start_idx = self.action_dim * 2
            end_idx = min(start_idx + len(torque), self.state_dim)
            state[start_idx:end_idx] = torque[:end_idx - start_idx]
        
        return state.tolist()
    
    def _build_virtual_state(self, chunk: List[float]) -> List[float]:
        """æ„å»ºè™šæ‹ŸçŠ¶æ€"""
        state = np.zeros(self.state_dim)
        
        # ä½¿ç”¨åŠ¨ä½œå—çš„ç¬¬ä¸€å¸§ä½œä¸ºå…³èŠ‚ä½ç½®
        state[:self.action_dim] = chunk[0]
        
        # è®¡ç®—é€Ÿåº¦ï¼ˆç®€åŒ–ï¼‰
        if len(chunk) > 1:
            velocity = np.array(chunk[1]) - np.array(chunk[0])
            state[self.action_dim:self.action_dim*2] = velocity
        
        return state.tolist()
    
    def __len__(self) -> int:
        return len(self.samples)
    
    def __getitem__(self, idx: int) -> Dict[str, Any]:
        sample = self.samples[idx]
        
        # ç¦ç”¨æ•°æ®å¢å¼º - ç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®
        action_chunk = torch.tensor(sample['action_chunk'], dtype=torch.float32)
        
        return {
            'instruction_id': torch.tensor(sample['instruction_id'], dtype=torch.long),
            'action_chunk': action_chunk,
            'state': torch.tensor(sample['state'], dtype=torch.float32),
            'task_name': sample['task_name'],
            'chunk_index': sample['chunk_index']
        }


class DiffusionTrainer:
    """
    Diffusion è®­ç»ƒå™¨ - æ”¯æŒæ ‡ç­¾å¹³æ»‘
    """
    
    def __init__(self, 
                 model: LargeBehaviorModel,
                 loss_fn: EnhancedDiffusionLoss,
                 optimizer: torch.optim.Optimizer,
                 scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None,
                 device: str = 'cuda',
                 save_dir: str = './checkpoints'):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            model: æ¨¡å‹
            loss_fn: æŸå¤±å‡½æ•°
            optimizer: ä¼˜åŒ–å™¨
            scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
            device: è®¾å¤‡
            save_dir: ä¿å­˜ç›®å½•
        """
        self.model = model.to(device)
        self.loss_fn = loss_fn.to(device)
        self.optimizer = optimizer
        self.scheduler = scheduler
        self.device = device
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(exist_ok=True)
        
        # è®­ç»ƒçŠ¶æ€
        self.epoch = 0
        self.global_step = 0
        self.best_loss = float('inf')
        
        # æ—©åœç›¸å…³
        self.patience = config.get('patience', 15)  # æ—©åœè€å¿ƒå€¼
        self.no_improvement_count = 0
        self.early_stopping = False
        
        # æ—¥å¿—è®°å½•
        self.train_losses = []
        self.val_losses = []
        self.task_losses = defaultdict(list)
    
    def train_epoch(self, 
                   dataloader: DataLoader,
                   epoch: int,
                   log_interval: int = 100) -> Dict[str, float]:
        """
        è®­ç»ƒä¸€ä¸ªepoch
        
        Args:
            dataloader: æ•°æ®åŠ è½½å™¨
            epoch: å½“å‰epoch
            log_interval: æ—¥å¿—é—´éš”
            
        Returns:
            è®­ç»ƒç»Ÿè®¡
        """
        self.model.train()
        epoch_losses = []
        task_losses = defaultdict(list)
        
        pbar = tqdm(dataloader, desc=f'Train Epoch {epoch}')
        
        for batch_idx, batch in enumerate(pbar):
            # æ•°æ®è½¬ç§»åˆ°è®¾å¤‡
            instruction_ids = batch['instruction_id'].to(self.device)
            action_chunks = batch['action_chunk'].to(self.device)
            states = batch['state'].to(self.device)
            task_names = batch['task_name']
            
            # æ¸…é›¶æ¢¯åº¦
            self.optimizer.zero_grad()
            
            # è®¡ç®—æŸå¤±
            loss_dict = self.loss_fn.compute_loss(
                model=self.model,
                x_start=action_chunks,
                instruction_ids=instruction_ids,
                state=states
            )
            
            loss = loss_dict['loss']
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            # æ›´æ–°å‚æ•°
            self.optimizer.step()
            
            # è®°å½•æŸå¤±
            epoch_losses.append(loss.item())
            
            # æŒ‰ä»»åŠ¡è®°å½•æŸå¤±
            for task_name in task_names:
                task_losses[task_name].append(loss.item())
            
            # æ›´æ–°å­¦ä¹ ç‡
            if self.scheduler is not None:
                self.scheduler.step()
            
            # æ—¥å¿—è®°å½•
            if batch_idx % log_interval == 0:
                avg_loss = np.mean(epoch_losses[-log_interval:])
                pbar.set_postfix({
                    'loss': f'{avg_loss:.6f}',
                    'lr': f'{self.optimizer.param_groups[0]["lr"]:.2e}'
                })
                
                # Wandbè®°å½•
                if HAS_WANDB and wandb.run is not None:
                    wandb.log({
                        'train_loss': avg_loss,
                        'learning_rate': self.optimizer.param_groups[0]['lr'],
                        'epoch': epoch,
                        'global_step': self.global_step
                    })
            
            self.global_step += 1
        
        # è®¡ç®—epochç»Ÿè®¡
        epoch_stats = {
            'mean_loss': np.mean(epoch_losses),
            'std_loss': np.std(epoch_losses),
            'min_loss': np.min(epoch_losses),
            'max_loss': np.max(epoch_losses)
        }
        
        # æŒ‰ä»»åŠ¡ç»Ÿè®¡
        for task_name, losses in task_losses.items():
            epoch_stats[f'{task_name}_mean_loss'] = np.mean(losses)
            self.task_losses[task_name].extend(losses)
        
        self.train_losses.extend(epoch_losses)
        
        return epoch_stats
    
    def validate(self, dataloader: DataLoader) -> Dict[str, float]:
        """
        éªŒè¯æ¨¡å‹
        
        Args:
            dataloader: éªŒè¯æ•°æ®åŠ è½½å™¨
            
        Returns:
            éªŒè¯ç»Ÿè®¡
        """
        self.model.eval()
        val_losses = []
        task_losses = defaultdict(list)
        
        with torch.no_grad():
            for batch in tqdm(dataloader, desc='Validation'):
                instruction_ids = batch['instruction_id'].to(self.device)
                action_chunks = batch['action_chunk'].to(self.device)
                states = batch['state'].to(self.device)
                task_names = batch['task_name']
                
                # è®¡ç®—æŸå¤±
                loss_dict = self.loss_fn.compute_loss(
                    model=self.model,
                    x_start=action_chunks,
                    instruction_ids=instruction_ids,
                    state=states
                )
                
                loss = loss_dict['loss'].item()
                val_losses.append(loss)
                
                # æŒ‰ä»»åŠ¡è®°å½•æŸå¤±
                for task_name in task_names:
                    task_losses[task_name].append(loss)
        
        # è®¡ç®—éªŒè¯ç»Ÿè®¡
        val_stats = {
            'mean_loss': np.mean(val_losses),
            'std_loss': np.std(val_losses),
            'min_loss': np.min(val_losses),
            'max_loss': np.max(val_losses)
        }
        
        # æŒ‰ä»»åŠ¡ç»Ÿè®¡
        for task_name, losses in task_losses.items():
            val_stats[f'{task_name}_mean_loss'] = np.mean(losses)
        
        self.val_losses.extend(val_losses)
        
        return val_stats
    
    def save_checkpoint(self, epoch: int, val_loss: float, is_best: bool = False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'global_step': self.global_step,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,
            'best_loss': self.best_loss,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'task_losses': dict(self.task_losses)
        }
        
        # ä¿å­˜å½“å‰æ£€æŸ¥ç‚¹
        checkpoint_path = self.save_dir / f'checkpoint_epoch_{epoch}.pth'
        torch.save(checkpoint, checkpoint_path)
        
        # ä¿å­˜æœ€ä½³æ£€æŸ¥ç‚¹
        if is_best:
            best_path = self.save_dir / 'best_model.pth'
            torch.save(checkpoint, best_path)
            self.best_loss = val_loss
            print(f"ğŸ¯ New best model saved with loss: {val_loss:.6f}")
    
    def train(self, 
             train_dataloader: DataLoader,
             val_dataloader: DataLoader,
             num_epochs: int,
             save_interval: int = 10,
             log_interval: int = 100,
             use_wandb: bool = False):
        """
        å®Œæ•´è®­ç»ƒæµç¨‹
        
        Args:
            train_dataloader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_dataloader: éªŒè¯æ•°æ®åŠ è½½å™¨
            num_epochs: è®­ç»ƒepochæ•°
            save_interval: ä¿å­˜é—´éš”
            log_interval: æ—¥å¿—é—´éš”
            use_wandb: æ˜¯å¦ä½¿ç”¨wandb
        """
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒ {num_epochs} epochs...")
        
        for epoch in range(num_epochs):
            self.epoch = epoch
            
            # è®­ç»ƒ
            train_stats = self.train_epoch(train_dataloader, epoch, log_interval)
            
            # éªŒè¯
            val_stats = self.validate(val_dataloader)
            
            # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
            print(f"\nğŸ“Š Epoch {epoch} Results:")
            print(f"  Train Loss: {train_stats['mean_loss']:.6f} Â± {train_stats['std_loss']:.6f}")
            print(f"  Val Loss: {val_stats['mean_loss']:.6f} Â± {val_stats['std_loss']:.6f}")
            
            # æŒ‰ä»»åŠ¡æ‰“å°ç»Ÿè®¡
            for key, value in train_stats.items():
                if 'mean_loss' in key and key != 'mean_loss':
                    task_name = key.replace('_mean_loss', '')
                    print(f"  {task_name} Train Loss: {value:.6f}")
            
            # Wandbè®°å½•
            if use_wandb and HAS_WANDB:
                wandb.log({
                    'epoch': epoch,
                    'train_mean_loss': train_stats['mean_loss'],
                    'val_mean_loss': val_stats['mean_loss'],
                    'val_std_loss': val_stats['std_loss']
                })
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            is_best = val_stats['mean_loss'] < self.best_loss
            
            # æ—©åœæ£€æŸ¥
            if is_best:
                self.no_improvement_count = 0
            else:
                self.no_improvement_count += 1
                
            if epoch % save_interval == 0 or is_best:
                self.save_checkpoint(epoch, val_stats['mean_loss'], is_best)
            
            # æ—©åœé€»è¾‘
            if self.no_improvement_count >= self.patience:
                print(f"\nâ¹ï¸ æ—©åœè§¦å‘: {self.patience} ä¸ªepochæ²¡æœ‰æ”¹å–„")
                print(f"æœ€ä½³éªŒè¯æŸå¤±: {self.best_loss:.6f}")
                self.early_stopping = True
                break
        
        print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")


def create_trainer(config: Dict[str, Any]) -> DiffusionTrainer:
    """
    åˆ›å»ºè®­ç»ƒå™¨
    
    Args:
        config: é…ç½®å­—å…¸
        
    Returns:
        è®­ç»ƒå™¨å®ä¾‹
    """
    # åˆ›å»ºæ¨¡å‹
    model = create_large_behavior_model(config.get('model_config', {}))
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    loss_fn = EnhancedDiffusionLoss(
        num_diffusion_steps=config.get('num_diffusion_steps', 1000),
        beta_schedule=config.get('beta_schedule', 'cosine'),
        smoothness_weight=config.get('smoothness_weight', 0.05),  # å‡å°‘å¹³æ»‘æ€§çº¦æŸ
        consistency_weight=config.get('consistency_weight', 0.02),  # å‡å°‘ä¸€è‡´æ€§çº¦æŸ
        velocity_weight=config.get('velocity_weight', 0.01)  # å‡å°‘é€Ÿåº¦çº¦æŸ
    )
    
    # åˆ›å»ºä¼˜åŒ–å™¨ - å¢åŠ L2æ­£åˆ™åŒ–
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config.get('learning_rate', 1e-4),
        weight_decay=config.get('weight_decay', 1e-3),  # å¢åŠ æƒé‡è¡°å‡
        betas=(0.9, 0.999)
    )
    
    # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=config.get('num_epochs', 100),
        eta_min=config.get('min_lr', 1e-6)
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨ - æ·»åŠ æ—©åœé…ç½®
    trainer_config = {
        'device': config.get('device', 'cuda'),
        'save_dir': config.get('save_dir', './checkpoints'),
        'patience': config.get('patience', 15)  # æ—©åœè€å¿ƒå€¼
    }
    
    trainer = DiffusionTrainer(
        model=model,
        loss_fn=loss_fn,
        optimizer=optimizer,
        scheduler=scheduler,
        **trainer_config
    )
    
    return trainer


def test_training_components():
    """æµ‹è¯•è®­ç»ƒç»„ä»¶"""
    print("æµ‹è¯•è®­ç»ƒç»„ä»¶...")
    
    # åˆ›å»ºè™šæ‹Ÿæ•°æ®
    batch_size = 4
    chunk_length = 16
    action_dim = 26
    state_dim = 60
    
    # åˆ›å»ºæ¨¡å‹
    model = create_large_behavior_model({
        'action_dim': action_dim,
        'chunk_length': chunk_length,
        'state_dim': state_dim,
        'diffusion_dim': 256,
        'num_diffusion_steps': 100
    })
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    loss_fn = EnhancedDiffusionLoss(num_diffusion_steps=100)
    
    # æµ‹è¯•æ•°æ®
    instruction_ids = torch.tensor([0, 1, 0, 1])
    state = torch.randn(batch_size, state_dim)
    action_chunks = torch.randn(batch_size, chunk_length, action_dim)
    
    # æµ‹è¯•æŸå¤±è®¡ç®—
    loss_dict = loss_fn.compute_loss(model, action_chunks, instruction_ids, state)
    print(f"æŸå¤±å½¢çŠ¶: {loss_dict['loss'].shape}")
    print(f"æŸå¤±å€¼: {loss_dict['loss'].item():.6f}")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
    trainer = DiffusionTrainer(model, loss_fn, optimizer, device='cpu')
    
    print("è®­ç»ƒç»„ä»¶æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    test_training_components()